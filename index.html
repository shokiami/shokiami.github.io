<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Sho Kiami</title>
    <link rel="icon" href="assets/sho.png">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Italiana&family=Nunito+Sans:opsz@6..12&display=swap">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div id="home">
      <div id="title-container">
        <div id="title">Hi, I'm Sho</div>
        <div id="subtitle">Engineer, Math Enthusiast, Cellist</div>
      </div>
    </div>

    <div id="navbar">
      <a id="navbar-title" href="">Shosuke Kiami</a>
      <ul id="section-menu">
        <li><a class="navlink" href="#home">Home</a></li>
        <li><a class="navlink" href="#about">About</a></li>
        <li>
          <a class="navlink" href="#projects">Projects</a>
          <div id="project-dropdown"><i class="dropdown-arrow"></i></div>
        </li>
        <ul id="project-menu" class="dropdown-menu">
          <li><a class="navlink" href="#dancetime">DanceTime</a></li>
          <li><a class="navlink" href="#alphafour">AlphaFour</a></li>
          <li><a class="navlink" href="#driverless-software">Driverless Software</a></li>
          <li><a class="navlink" href="#genaug">GenAug</a></li>
          <li><a class="navlink" href="#geoknowr">GeoKnowr</a></li>
          <li><a class="navlink" href="#frijma">Frijma</a></li>
          <li><a class="navlink" href="#project-sidewalk">Project Sidewalk</a></li>
          <li><a class="navlink" href="#danzon">Danz√≥n No. 2</a></li>
          <li><a class="navlink" href="#cinema-paradiso">Cinema Paradiso</a></li>
          <li><a class="navlink" href="#cello">Cello</a></li>
        </ul>
        <li><a href="assets/shokiami_resume.pdf" target="_blank">Resume</a></li>
        <li><a class="navlink" href="#contact">Contact</a></li>
      </ul>
    </div>

    <div id="main">
      <div id="about" class="section">
        <div class="header">About Me</div>
        <div class="date"></div>
        <div class="subsection">
          <img id="head-shot" width="200px" src="assets/sho.png">
          <div class="text">
            I am a student at the University of Washington passionate about mechanical engineering, computer science,
            mathematics, and cello.
          </div>
          <div class="text">
            I started off my undergraduate studies double-majoring in CS and math, receiving early industry experience at
            companies such as Microsoft and Apple along with research experience in labs across fields including
            computational biology, computer vision, and deep robotic learning.
          </div>
          <div class="text">
            Midway through undergrad, I was reminded of my long-term curiosity for ME and decided to pivot my education.
            Luckily, since I had already mostly finished my CS and math degree, the university actually allowed me to
            keep all three majors.
            Today, I continue to further my passion for ME through my work as suspension engineer on UW Formula Motorsports
            and robotics researcher in the UW WEIRD lab.
          </div>
          <div class="text">
            Outside of school, my main hobby is playing the cello. I started when I was four years old and still play avidly
            today. Otherwise, I also enjoy playing other instruments (piano and guitar), music composition, calisthenics,
            skiing, drawing, and cooking.
          </div>
        </div>
      </div>
      
      <div id="projects" class="section">
        <div class="header">Projects</div>
        <div class="date"></div>
        <div class="subsection">
          <div id="project-list">
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Driverless Steering</div>
                <div class="project-date">Jul 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail in-progress" src="assets/driverless_steering/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Design and manufacturing of driverless steering assembly and gearbox.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Drawing Robot</div>
                <div class="project-date">Aug 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail" src="assets/drawing_robot/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Design and manufacturing of a robotic arm that can draw any image of choice.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Grasping in Clutter</div>
                <div class="project-date">Mar 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail" src="assets/grasping_in_clutter/thumbnail.jpg">
                </div>
                <div class="project-description">
                   RL algorithms for teaching a robotic arm + hand to grasp objects in clutter.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#dancetime">
                <div class="project-title">DanceTime</div>
                <div class="project-date">May 2021 - Jul 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/dancetime/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Multiplayer dance-based rhythm game inspired by Just Dance and FaceTime.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#alphafour">
                <div class="project-title">AlphaFour</div>
                <div class="project-date">Jun 2022 - Jul 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/alphafour/thumbnail.jpg">
                </div>
                <div class="project-description">
                  AI that learns to play Connect 4 from scratch via self-play deep reinforcement learning.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#driverless-software">
                <div class="project-title">Driverless Software</div>
                <div class="project-date">Jan 2023 - May 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/driverless_software/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Control and planning algorithms for a driverless formula race car.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#genaug">
                <div class="project-title">GenAug</div>
                <div class="project-date">Jan 2023 - Mar 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/genaug/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Training a robot to perform pick-place tasks with imitation learning and generative models.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#geoknowr">
                <div class="project-title">GeoKnowr</div>
                <div class="project-date">Nov 2022 - Dec 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/geoknowr/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Data collection, training, and evaluation pipeline for a light-weight GeoGuessr AI.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#frijma">
                <div class="project-title">Frijma</div>
                <div class="project-date">Oct 2022 - Oct 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/frijma/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Web app where you can scan receipts and keep track of expiration dates.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#project-sidewalk">
                <div class="project-title">Project Sidewalk</div>
                <div class="project-date">Jun 2020 - Jun 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/project_sidewalk/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Data crowdsourcing and computer vision pipeline for sidewalk accessibility evaluation.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#danzon">
                <div class="project-title">Danz√≥n No. 2</div>
                <div class="project-date">Jul 2019 - Aug 2021</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/danzon/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Arrangement of Arturo M√°rquez's Danz√≥n No. 2 for two cellos.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#cinema-paradiso">
                <div class="project-title">Cinema Paradiso</div>
                <div class="project-date">Aug 2020 - Feb 2021</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/cinema_paradiso/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Variations on Ennio Morricone's Cinema Paradiso for two cellos.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="navlink" href="#cello">
                <div class="project-title">Cello</div>
                <div class="project-date">Nov 2005 - Present</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/cello/thumbnail.jpg">
                </div>
                <div class="project-description">
                  Some random videos of me playing cello with friends.
                </div>
              </a>
            </div>
          </div>
        </div>
      </div>

      <div id="dancetime" class="section">
        <div class="header">DanceTime</div>
        <div class="date">May 2021 - Jul 2023</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            DanceTime is a multiplayer dance-based rhythm game inspired by Just Dance and FaceTime. In DanceTime,
            each player must try to follow the dance moves of the avatar, and the closer you are, the more points you get.
            This is one of my most technical projects as it features a custom 30 Hz pose estimation library and an original
            regression-based scoring algorithm.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/dancetime/dancing.mp4" type="video/mp4"/>
              </video>
              <div class="caption">
                My friend Tim Erwin and I playing DanceTime.
              </div>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Code: <a href="https://github.com/shokiami/DanceTime" target="_blank">https://github.com/shokiami/DanceTime</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Language: C++</li>
            <li>CV Library: OpenCV</li>
            <li>ML Library: MediaPipe, TensorFlow Lite</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">System Overview</div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/dancetime/flow.jpg">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Algorithms</div>
          <div class="text">
            One algorithm I wanted to highlight was the scoring algorithm which solves a simple yet non-trivial problem:
          </div>
          <div class="text">
            Define a pose to be a set of (x, y) coordinates for various key joints/body parts. Given a constant stream
            of noisy pose readings, how can we arrive at a score which captures how similarly the two players danced?
          </div>
          <div class="text">
            There were three main nuances which made this problem challenging:
          </div>
          <ul class="list">
            <li>Invariance: translation/scaling should not affect scoring.</li>
            <li>Noise: the pose data can be very jittery/sporadic.</li>
            <li>Timing offset: scoring cannot fixate on current poses and must account for timing offsets.</li>
          </ul>
          <div class="text">
            Invariance was the easiest problem to address. I tried various strategies such as comparing joint velocities and
            joint angles, but both of these failed due to the noise. What worked best was standardizing each pose such that
            the torso had unit length and was centered at the origin.
          </div>
          <div class="text">
            Noise was the hardest problem to combat. The first natural step was to use a moving average, but this ended
            up either not making a significant enough impact or over-dampening the overall shape of the data.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/dancetime/1.jpg">
              <div class="caption">
                Example left wrist x coordinate vs. time data standardized to [-1, 1].
              </div>
            </div>
          </div>
          <div class="text">
            So instead, I came up with a two part solution. The first part is a conditional moving average which only
            averages if a current point is further from its neighbors than they are to each other (these points are
            defined to be outliers). This does a better job preserving the shape of the data.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/dancetime/2.jpg">
              <div class="caption">
                Outliers set to average of their neighbors and marked with an "X".
              </div>
            </div>
          </div>
          <div class="text">
            The second part is using regression to find the polynomial of best fit for the data. The intuition is that this would help
            capture the player's overall trajectory and significantly reduce the affect of any remaining noise in our data.
            After lots of experimentation, I found that a polynomial degree of 3 provided the best results without overfitting.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/dancetime/3.jpg">
              <div class="caption">
                A cubic polynomial is fitted to the data using regression.
              </div>
            </div>
          </div>
          <div class="text">
            Using polynomial regression actually serves a second purpose in helping address the timing offset issue by
            transforming our problem to continuous space, making it easy to find the horizontal translation that
            minimizes the polynomials errors.
            I ended up using maximum error instead of mean error since it is a more accurate measure of alignment.
            Finally, we can take the error and offset and feed them into some activation function such as a sigmoid
            to get a similarity score between 0 and 1.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/dancetime/4.mp4" type="video/mp4"/>
              </video>
              <div class="caption">
                The red and blue functions are identical cubic functions that are vertically offset and the green function
                and orange function are the mean and max error respectively over the interval [-1, 1]. Note that the max error
                is minimized at offset zero which is desired.
              </div>
            </div>
          </div>
          <div class="text">
            Here is the full pseudocode for the entire scoring algorithm:
          </div>
          <pre class="algo">
score(player_poses, avatar_poses):
  remove_outliers(player_poses)
  remove_outliers(player_poses)
  standardize(player_poses)
  standardize(avatar_poses)
  player_polys = poly_regression(player_poses)
  avatar_polys = poly_regression(avatar_poses)
  min_error = infinity
  for t from T_MIN to T_MAX with T_STEP:
    error = max_error(player_polys.translate(t), avatar_polys)
    if error < min_error:
      min_error = error
      offset = |t|
  score = sigmoid(min_error + OFFSET_COST * offset)
  return score

remove_outliers(poses):
  for pose in poses:
    for body_part in pose:
      prev_to_curr = dist(prev_body_part, body_part)
      curr_to_next = dist(body_part, next_body_part)
      pev_to_next = dist(prev_body_part, next_body_part)
      if prev_to_next < prev_to_curr or prev_to_next < curr_to_next:
        body_part = (prev_body_part + next_body_part) / 2

standardize(poses):
  for pose in poses:
    left_shoulder = pose[left_shoulder]
    right_shoulder = pose[right_shoulder]
    left_hip = pose[left_hip]
    right_hip = pose[right_hip]
    torso_center = (left_shoulder + left_hip + right_shoulder + right_hip) / 4
    left_torso_length = dist(left_shoulder, left_hip)
    right_torso_length = dist(right_shoulder, right hip)
    torso_length = (left_torso_length + right_torso_length) / 2
    for body_part in pose:
      body_part = (body_part - torso_center) / left_torso_length

poly_regression(poses):
  polys = {}
  for body_part in body_parts:
    A = matrix(poses.length, POLY_DEGREE + 1)
    b = vector(poses.length)
    for i from 0 to poses.length:
      A[i] = [1, i, i^2, ..., i^POLY_DEGREE]
      b[i] = poses[i][body_part]
    P = A * (A^T * A)^-1 * A^T
    proj_b = P * b
    poly_coeffs = A^-1 * proj_b
    polys[body_part] = poly_coeffs
  return polys

max_error(player_polys, avatar_polys):
  max_error = -infinity
  for body_part in body_parts:
    for t from T_START to T_END with T_STEP:
      f = player_polys[body_part]
      g = avatar_polys[body_part]
      error = (f(t) - g(t))^2
      if error > max_error:
        max_error = error
  return max_error
          </pre>
        </div>
      </div>

      <div id="alphafour" class="section">
        <div class="header">AlphaFour</div>
        <div class="date">Jun 2022 - Jul 2023</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            AlphaFour is a Connect 4 AI that learns how to play from scratch via self-play deep reinforcement learning.
            After 20 generations (~9 hours of training), AlphaFour is able to play at ~90% optimality.
            Furthermore, since the only input to the algorithm is the rules of the game, AlphaFour can even generalize to
            other board games.
            As suggested by the name, AlphaFour is heavily inspired by DeepMind's AlphaZero.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Code: <a href="https://github.com/shokiami/AlphaFour" target="_blank">https://github.com/shokiami/AlphaFour</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Language: Python</li>
            <li>ML Library: PyTorch</li>
            <li>GUI Library: PyGame</li>
            <li>Util Libraries: NumPy, Matplotlib</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Model</div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/alphafour/resnet.jpg">
              <div class="caption">
                AlphaFour's model consisted of a deep residual network of 8 res blocks with 128 channels whose output
                is fed into a policy network and a value network.
              </div>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Algorithms</div>
          <pre class="algo">
mcts(state):
          </pre>
        </div>
        <div class="subsection">
          <div class="subheader">Results</div>
          <div class="text">
            Here is the loss vs. epoch plot after training for 20 generations (~9 hours):
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/alphafour/loss.jpg">
            </div>
          </div>
          <div class="text">
            Those who are familiar with machine learning might wonder what all of the little spikes are. Each of the spikes
            correspond to new generations. When a new set of self-play games are generated, the model's train loss essentially
            jumps up to its test loss. Nevertheless, it's still cool to see the overall converging nature of the plot.
          </div>
          <div class="text">
            To demonstrate that the AI is indeed learning, here are some example games where player one is an optimal player
            and player two is AlphaFour at different stages during its training.
            Note that Connect 4 is a solved game, so playing against an optimal player (who plays first) is impossible to
            win against. Thus, how many moves the AI survives is a rough metric of how well it is playing.
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <div class="image-title">
                Generation 0 vs. Optimal Player (7 moves)
              </div>
              <img width="100%" src="assets/alphafour/0_vs_opt.gif">
            </div>
            <div image="image" style="width: 45%;">
              <div class="image-title">
                Generation 5 vs. Optimal Player (17 moves)
              </div>
              <img width="100%" src="assets/alphafour/5_vs_opt.gif">
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <div class="image-title">
                Generation 10 vs. Optimal Player (31 moves)
              </div>
              <img width="100%" src="assets/alphafour/10_vs_opt.gif">
            </div>
            <div class="image" style="width: 45%;">
              <div class="image-title">
                Generation 20 vs. Optimal Player (37 moves)
              </div>
              <img width="100%" src="assets/alphafour/20_vs_opt.gif">
            </div>
          </div>
          <div class="text">
            Checking AlphaFour's moves against a Connect 4 solver, we see that ~90% of the generation 20 moves are optimal.
            Even better, it turns out that if the optimal player makes a single suboptimal move, AlphaFour can play
            optimally enough to convert the game into a win.
            In the following game, first player plays optimally except for move 5 in which it plays the third best move.
            Here, AlphaFour is able to take advantage of this mistake to win the game with an impressive 5 in a row.
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <div class="image-title">
                Generation 20 vs. Optimal Player w/ 1 Mistake (40 moves)
              </div>
              <img width="100%" src="assets/alphafour/20_vs_subopt.gif">
            </div>
          </div>
        </div>
      </div>

      <div id="driverless-software" class="section">
        <div class="header">Driverless Software</div>
        <div class="date">Jan 2023 - May 2023</div>
        <div class="text">
          Sed risus pretium quam vulputate dignissim suspendisse. Sem fringilla ut morbi tincidunt augue interdum. Orci dapibus ultrices in iaculis nunc sed. Vitae justo eget magna fermentum iaculis eu non diam phasellus. Quam id leo in vitae turpis massa sed. Commodo viverra maecenas accumsan lacus vel facilisis volutpat est velit. Vitae congue eu consequat ac felis donec et odio pellentesque. Aliquam vestibulum morbi blandit cursus risus. Enim eu turpis egestas pretium aenean pharetra magna. Libero volutpat sed cras ornare arcu dui vivamus. Velit scelerisque in dictum non consectetur a erat. Sed cras ornare arcu dui vivamus arcu felis bibendum ut. Purus faucibus ornare suspendisse sed nisi lacus sed viverra tellus. Senectus et netus et malesuada. Enim praesent elementum facilisis leo vel fringilla est ullamcorper eget. Sit amet facilisis magna etiam tempor. <br><br>
          Erat velit scelerisque in dictum non consectetur. At lectus urna duis convallis convallis tellus id. Ut pharetra sit amet aliquam id diam. Lectus sit amet est placerat. Consectetur adipiscing elit duis tristique sollicitudin nibh sit amet. Vitae congue eu consequat ac felis. Egestas integer eget aliquet nibh praesent tristique. Ut eu sem integer vitae justo eget magna fermentum. Eget duis at tellus at urna condimentum mattis. Sit amet luctus venenatis lectus magna fringilla. Enim diam vulputate ut pharetra sit amet aliquam id diam. Nisl nunc mi ipsum faucibus vitae aliquet. Fermentum dui faucibus in ornare quam viverra. Curabitur gravida arcu ac tortor. Id consectetur purus ut faucibus. <br><br>
          Adipiscing elit ut aliquam purus sit amet luctus venenatis lectus. Ipsum a arcu cursus vitae congue mauris rhoncus. Quam viverra orci sagittis eu volutpat odio. Imperdiet sed euismod nisi porta lorem mollis aliquam ut. Eget dolor morbi non arcu risus quis varius quam. Blandit libero volutpat sed cras ornare arcu dui. Metus vulputate eu scelerisque felis imperdiet. Eget egestas purus viverra accumsan in nisl nisi scelerisque. Rhoncus mattis rhoncus urna neque viverra. Arcu non sodales neque sodales ut. Sed ullamcorper morbi tincidunt ornare massa. Hac habitasse platea dictumst vestibulum rhoncus est pellentesque elit ullamcorper. Odio euismod lacinia at quis risus sed. Nunc vel risus commodo viverra. Sed euismod nisi porta lorem mollis aliquam ut. Lobortis scelerisque fermentum dui faucibus in. Ultricies integer quis auctor elit sed vulputate mi sit. Id cursus metus aliquam eleifend mi in. <br><br>
          Adipiscing elit ut aliquam purus sit. Bibendum est ultricies integer quis auctor. A erat nam at lectus urna duis convallis convallis. Quam nulla porttitor massa id neque. Pretium lectus quam id leo in. Sit amet mauris commodo quis. Tristique nulla aliquet enim tortor. Cursus turpis massa tincidunt dui ut. Praesent elementum facilisis leo vel fringilla. Vestibulum lorem sed risus ultricies tristique nulla aliquet. <br><br>
          Interdum posuere lorem ipsum dolor sit amet consectetur. Lobortis elementum nibh tellus molestie nunc non blandit. Augue eget arcu dictum varius. Pulvinar sapien et ligula ullamcorper. Egestas sed tempus urna et pharetra pharetra. Consectetur libero id faucibus nisl tincidunt eget nullam non nisi. Orci phasellus egestas tellus rutrum. Felis eget nunc lobortis mattis aliquam faucibus purus in massa. Ut faucibus pulvinar elementum integer enim neque volutpat ac. Tortor id aliquet lectus proin nibh nisl condimentum id venenatis. Ac turpis egestas maecenas pharetra convallis posuere morbi. Id interdum velit laoreet id donec ultrices tincidunt arcu non. Nulla at volutpat diam ut venenatis tellus in. Nibh mauris cursus mattis molestie a iaculis at erat. At ultrices mi tempus imperdiet nulla malesuada pellentesque elit eget. Mattis enim ut tellus elementum sagittis vitae et leo duis. Turpis egestas pretium aenean pharetra magna ac placerat vestibulum lectus. Auctor eu augue ut lectus arcu bibendum at varius vel. Egestas erat imperdiet sed euismod nisi porta. Justo laoreet sit amet cursus. <br><br>
          Cursus risus at ultrices mi tempus imperdiet nulla malesuada pellentesque. Gravida in fermentum et sollicitudin ac. Diam maecenas ultricies mi eget. Id donec ultrices tincidunt arcu non sodales neque sodales. Curabitur vitae nunc sed velit dignissim sodales ut. Lacus viverra vitae congue eu. Lacus vel facilisis volutpat est velit egestas dui. Facilisi nullam vehicula ipsum a arcu cursus vitae congue. Enim nunc faucibus a pellentesque sit amet porttitor eget dolor. Imperdiet sed euismod nisi porta lorem mollis aliquam. Ultricies leo integer malesuada nunc. Viverra vitae congue eu consequat ac felis donec et odio. Non enim praesent elementum facilisis leo vel fringilla est. Enim eu turpis egestas pretium aenean pharetra magna. Cursus mattis molestie a iaculis at erat pellentesque adipiscing commodo. Augue mauris augue neque gravida in. Non curabitur gravida arcu ac tortor dignissim convallis aenean et. Dictum sit amet justo donec enim diam vulputate ut. Justo eget magna fermentum iaculis eu non. Ac tortor vitae purus faucibus. <br><br>
          Est sit amet facilisis magna etiam. Tristique et egestas quis ipsum suspendisse ultrices gravida. Senectus et netus et malesuada fames. Nec feugiat in fermentum posuere. Et molestie ac feugiat sed lectus vestibulum mattis ullamcorper velit. Fames ac turpis egestas integer eget aliquet nibh praesent tristique. Faucibus nisl tincidunt eget nullam non. Adipiscing commodo elit at imperdiet dui accumsan sit amet nulla. Turpis nunc eget lorem dolor sed viverra ipsum nunc. Nunc faucibus a pellentesque sit amet porttitor. Neque ornare aenean euismod elementum nisi quis eleifend. Nunc sed id semper risus in hendrerit gravida rutrum quisque. Consequat semper viverra nam libero justo. <br><br>
          In nisl nisi scelerisque eu ultrices vitae. Tellus at urna condimentum mattis. Tortor pretium viverra suspendisse potenti nullam ac tortor vitae. Quisque sagittis purus sit amet volutpat consequat mauris nunc congue. Purus ut faucibus pulvinar elementum integer enim. Vitae proin sagittis nisl rhoncus mattis rhoncus urna neque. Ridiculus mus mauris vitae ultricies leo integer malesuada nunc vel. Pellentesque habitant morbi tristique senectus et. Dictumst vestibulum rhoncus est pellentesque. Ac tortor dignissim convallis aenean et tortor.
        </div>
      </div>

      <div id="genaug" class="section">
        <div class="header">GenAug</div>
        <div class="date">Jan 2023 - Mar 2023</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Suppose you want a robotic arm that when told "put the cup on the coaster" or "put the small box in the larger box"
            is able to perform the task first try. While imitation learning provides one method of training a robot to
            perform manipulation tasks, since collecting real-world examples is expensive, the training data will likely
            contain limited objects/scenes, preventing the robot from generalizing to novel scenarios.
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/genaug/pipeline.jpg">
            </div>
          </div>
          <div class="text">
            GenAug was a solution proposed by PhD student Zoey Chen (a colleague from the UW WEIRD Lab) who asked me to
            join her on the project. The idea behind GenAug is to use generative models such as stable diffusion
            to augment the training data (replace the pick object, replace the place object, alter the scene, add distractors, etc.).
            Our hope was that the large amounts of web-scraped data these generative models were trained on would serve
            as a prior and thus provide more semantically meaningful augmentation than classical data augmentation
            techniques (noise injection, transformations, etc.).
            Sure enough, in our real-world experiments, we found that GenAug improved our robot's zero-shot success rate
            by 40%, allowing our robot to perform general table-top manipulation tasks with minimal human demonstrations.
            Our results were published in a paper that was accepted to the Robotics Science and Systems conference in
            Jun 2023 and was a Best System Paper Finalist.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Website: <a href="https://genaug.github.io" target="_blank">https://genaug.github.io</a></li>
            <li>Code: <a href="https://github.com/genaug/genaug" target="_blank">https://github.com/genaug/genaug</a></li>
            <li>Paper: <a href="https://arxiv.org/abs/2302.06671" target="_blank">https://arxiv.org/abs/2302.06671</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Hardware: 6 DoF xArm5 w/ Vacuum Gripper, Intel RealSense Camera (D435i)</li>
            <li>Languages: Python, Bash</li>
            <li>Robotics Library: ROS</li>
            <li>Sim Library: PyBullet</li>
            <li>ML Library: PyTorch</li>
            <li>Paper: LaTeX</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            To collect human demonstrations, the user labels pick/place locations on a 2D top-down projection of the
            scene point cloud. These locations are mapped back to 3D coordinates using calibrated depth maps.
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/genaug/setup.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/datacollection.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Data Augmentation</div>
          <div class="text">
            We used GenAug to augment our dataset in the following ways:
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/distractor.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/table.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/object.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/texture.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Zero-Shot Deployment</div>
          <div class="text">
            After training our model on the augmented dataset, we test it on our robot on scenes it has never seen before.
            Here are some examples from our testing:
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/bowl2bowl.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/bowl2coaster.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <video width="100%" autoplay loop muted>
                <source src="assets/genaug/box2basket.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Video</div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/MxcmKKvdBhk" class="youtube">
              <img class="youtube-thumbnail" src="assets/genaug/video_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Publication</div>
          <div class="pdf-container">
            <a class="pdf" href="assets/genaug/paper.pdf" target="_blank">
              <img class="pdf-thumbnail" src="assets/genaug/paper_thumbnail.jpg">
              <img class="pdf-open" src="assets/icons/pdf-open.png">
            </a>
          </div>
        </div>
      </div>

      <div id="geoknowr" class="section">
        <div class="header">GeoKnowr</div>
        <div class="date">Nov 2022 - Dec 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            GeoKnowr is a lightweight GeoGuessr AI that can reliably guess within 2000 km of the groun truth.
          </div>
          <div class="text">
            For those who are unfamiliar, <a href="https://www.geoguessr.com/" target="_blank">GeoGuessr</a>
            is a popular web game where users are thrown into random locations around the world in
            Google Street View and are challenged to place a marker on the world map to guess where they are in the world
            (the closer you guess, the more points you get).
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/geoknowr/geoguessr.jpg">
              <div class="caption">
                Example screenshot from GeoGuessr (this is Japan).
              </div>
            </div>
          </div>
          <div class="text">
            My friend Zach Chapman and I wanted to use deep learning to create a GeoGuessr AI that would be able to
            reliably guess the location of where such images were taken. Furthermore, GeoGuessr has several different modes,
            one of which is NMPZ (no moving-panning-zooming) which is notoriously the most difficult and thus the one we wanted to tackle.
            We created the entire data collection, training, and testing pipeline from scratch.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Code: <a href="https://github.com/shokiami/GeoKnowr" target="_blank">https://github.com/shokiami/GeoKnowr</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Languages: Python, JavaScript, HTML, CSS</li>
            <li>Street View API: Google Street View</li>
            <li>ML Libraries: PyTorch, Scikit-learn</li>
            <li>Util Libraries: NumPy, Pandas, Matplotlib, WebGL</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            Our data colelction pipeline could be broken up into the following steps:
          </div>
          <ol class="list">
            <li>Choose a random (latitude, longitude) coordinate.</li>
            <li>Use Google's API's to see if any Google Street View locations exist within a 10km search radius.</li>
            <li>If so, grab the metadata for that location and scrape the corresponding street view image at a random heading.</li>
            <li>Repeat steps 1-3 until we gather enough data.</li>
          </ol>
          <div class="text">
            Using this method, we downloaded a total of 32,000 images with resolution 480x360 from around the world.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Training</div>
          <div class="text">
            Initially, we framed this as a regression problem, with the goal of minimizing surface distance around the
            unit sphere because this is ultimately the criterion we are trying to minimize when playing GeoGuessr.
            However, the issue with this was that our model would learn to spam Greenland. This made sense because most
            of the Google's street view data is in the northern hemisphere and thus our model could achieve a decent
            score by average guessing.
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/geoknowr/coverage.jpg">
              <div class="caption">
                Google Street View's coverage.
              </div>
            </div>
          </div>
          <div class="text">
            To combat this issue, we reframed the problem as classification by dividing up the globe into numerous regions.
            The idea was that the model would classify an image into one of these regions and then guess the center of the region.
            This forced our model to commit more, as nearby regions are equally penalized as regions on the opposite side of the world.
            Another motivation behind this pivot was the recognition that humans also play GeoGuessr by region-guessing.
          </div>
          <div class="text">
            First we tried dividing up the world into a uniform grid, however, the majority of these classes had little to no
            examples being over water or in areas with low GSV coverage, so our model would learn to spam the majority class.
            We addressed this by cleverly using clustering algorithms to perform the class divisions for us, leading to more
            equal sized classes (and less data sparsity). Note how the clusters line up with Google's coverage.
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/geoknowr/clusters.jpg">
              <div class="caption">
                Visualziation of our clusters. We found that the Gaussian mixture model worked the best and 21 classes
                was the sweet spot where less classes led to regions which were too large and more classes led to too
                little examples per class.
              </div>
            </div>
          </div>
          <div class="text">
            Our final performance boost came from recognizing that we did not have enough data to adequately train a
            deep neural network from scratch, and so we used transfer learning on ResNet-18 pretrained on the ImageNet
            dataset. Now, our model no longer had to learn feature extraction and could instead focus on finding
            the relationship between the features provided by pretrained ResNet-18 and our classes.
          </div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/geoknowr/resnet18.jpg">
              <div class="caption">
                Transfer learning on ResNet-18 architecture.
              </div>
            </div>
          </div>
          <div class="text">
            Throughout this entire process, we also used an abundance of deep learning techniques such as learning rate
            annealing and weight decay.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Results</div>
          <div class="text">
            Here are our results after training for ~5 hours:
          </div>
          <ul class="list">
            <li>5th percentile: 361.33km (correct part of country)</li>
            <li>10th percentile: 520.11km (correct country)</li>
            <li>25th percentile: 980.21km (correct region)</li>
            <li>Median: 2839.96km (correct continent)</li>
          </ul>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/distances.jpg">
            </div>
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/loss.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/accuracy.jpg">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Examples</div>
          <div class="text">
            Here are 10 example images and corresponding guesses from our model.
            The red marker represents the ground truth and the grey marker represents the AI's guess.
          </div>
          <div class="image-title">
            Eurajoki, Finland: 46.15km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/1a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/1b.jpg">
            </div>
          </div>
          <div class="image-title">
            Cedar Pocket, Australia: 766.68km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/2a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/2b.jpg">
            </div>
          </div>
          <div class="image-title">
            ≈ådai, Japan: 554.07km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/3a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/3b.jpg">
            </div>
          </div>
          <div class="image-title">
            Pervomaiskii, Russia: 750.37km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/4a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/4b.jpg">
            </div>
          </div>
          <div class="image-title">
            Clavering √òer, Greenland: 3001.91km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/5a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/5b.jpg">
            </div>
          </div>
          <div class="image-title">
            Nuenen, Netherlands: 728.77km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/6a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/6b.jpg">
            </div>
          </div>
          <div class="image-title">
            Tanjung Mulia, Indonesia: 778.63km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/7a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/7b.jpg">
            </div>
          </div>
          <div class="image-title">
            Takper, Nigeria: 860.73km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/8a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/8b.jpg">
            </div>
          </div>
          <div class="image-title">
            Colonia R√≠o Escondido, M√©xico: 26.80km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/9a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/9b.jpg">
            </div>
          </div>
          <div class="image-title">
            Chipaya, Bolivia: 1133.61km away
          </div>
          <div class="image-container">
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/10a.jpg">
            </div>
            <div class="image" style="width: 45%;">
              <img width="100%" src="assets/geoknowr/10b.jpg">
            </div>
          </div>
        </div>
      </div>

      <div id="frijma" class="section">
        <div class="header">Frijma</div>
        <div class="date">Oct 2022 - Oct 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Frijma is a web app that allows users to scan grocery receipts using their phone camera, keeps track of their
            expiration dates with easily digestible visuals, and also provides recipe inspiration for efficient meal
            planning‚Äîultimately reducing food waste due to food items exceeding their expiration date.
          </div>
          <div class="text">
            Frijma was a submission to the 24-hour DubHacks'22 hackathon. My team consisted of me, Stefan Todoran,
            Nicholas Bradley, and Zach Chapman.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Frijma: <a href="https://todoran.dev/frijma" target="_blank">https://todoran.dev/frijma</a></li>
            <li>Code: <a href="https://github.com/StefanTodoran/frijma" target="_blank">https://github.com/StefanTodoran/frijma</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Languages: TypeScript, Javascript, HTML, CSS</li>
            <li>Food Dataset: <a href="https://www.fsis.usda.gov/shared/data/EN/" target="_blank">US Department of Agriculture</a></li>
            <li>Image to Text: Tesseract.js</li>
            <li>Recipe API: Edamam</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">System Overview</div>
          <div class="image-container">
            <div class="image" style="width: 90%;">
              <img width="100%" src="assets/frijma/flow.jpg">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">User Experience</div>
          <div class="text">
            1. Suppose you go grocery shopping and return with the following receipt (I just found this online).
          </div>
          <div class="image-container">
            <div class="image" style="width: 10%;">
              <img width="100%" src="assets/frijma/receipt.jpg">
              <div class="caption">
                An example grocery receipt.
              </div>
            </div>
          </div>
          <div class="text">
            2. You can either take a photo or upload an image of the receipt.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/frijma/scan.jpg">
              <div class="caption">
                The scan/upload button can be found at the top of the webpage.
              </div>
            </div>
          </div>
          <div class="text">
            3. Frijma provides a list of all of the groceries detected on the receipt with their expiration dates.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/frijma/result.jpg">
              <div class="caption">
                Frijma's list of food items and their expiration dates.
              </div>
            </div>
          </div>
          <div class="text">
            4. Frijma also provides a list of relevant recipes to help use up all of your groceries on time.
          </div>
          <div class="image-container">
            <div class="image" style="width: 60%;">
              <img width="100%" src="assets/frijma/recipes.jpg">
              <div class="caption">
                Frijma's list of recipe inspiration.
              </div>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Algorithms</div>
          <div class="text">
            Although I worked on the entire pipeline, the I focused on the parsing, search, and edit-distance
            algorithms. The runtime of the three combined algorithms is O(mn) where m is the number of characters in the receipt
            and n is the number of characters in the dataset (note that this is the optimal runtime).
            Here is the pseudocode for the three algorithms:
          </div>
          <pre class="algo">
parse(receipt):
  for line in receipt:
    if line satisfies regex "*XX.XX":
      abbrv = line.remove(non-letters)
      if abbrv == "":
        continue
      food, cost = search(abbrv)
      if cost > MAX_COST:
        continue
      addToVisual(food)
      queryRecipes(food)

search(abbrv):
  min_cost = infinity
  closest_food = null
  for keywords, food in dataset:
    total_cost = 0
    for word in abbrv:
      keyword_min_cost = infinity
      for keyword in keywords:
        keyword_cost = edit_distance(word, keyword)
        if keyword_cost < keyword_min_cost:
          keyword_min_cost = keyword_cost
      total_cost += keyword_min_cost
    avg_cost = total_cost / abbrv.word_count
    name_cost = edit_distance(abbrv, food)
    true_cost = (P * name_cost + (1 - P) * avg_cost) / abbrv.length
    if true_cost < min_cost:
      closest_food = food
      min_cost = true_cost
  return closest_food, min_cost

edit_distance(abbrv, food):
  dp = zero_matrix(abbrv.length + 1, food.length + 1)
  for i from 0 to abbrv.length:
    for j from 0 to food.length:
      if i == 0:
        dp[i, j] = j * INSERTION_COST
      else if j == 0:
        dp[i, j] = i * DELETION_COST
      else if abbrv[i - 1] == food[j - 1]:
        dp[i, j] = dp[i - 1, j - 1]
      else:
        dp[i, j] = min(
          dp[i][j - 1] + INSERTION_COST,
          dp[i - 1][j] + DELETION_COST,
          dp[i - 1][j - 1] + INSERTION_COST + DELETION_COST
        )
  return dp[abbrv.length, food.length]
          </pre>
        </div>
      </div>

      <div id="project-sidewalk" class="section">
        <div class="header">Project Sidewalk</div>
        <div class="date">Sep 2021 - Jun 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            In 2020, I joined the UW Makeability Lab as a software engineer, co-developing the Project Sidewalk webpage:
            a gameified website where users walk around in Google Street View and label sidewalk accessibility issues for wheelchair
            users and older adults. Since deployment, we were able to build a never-seen-before dataset of 1 million labels
            across 8 cities.
          </div>
          <div class="text">
            In 2021, I joined forces with my friends Michael and Logan to apply deep learning to the above dataset to
            create a computer vision pipeline for automatic sidwealk evaluation. As a culmination of our work, we authored
            a paper discussing the effects of filtered vs. unfiltered and single-city vs. cross-city training data and
            how our models can label new cities with a promising 80-90% accuracy. Our paper was accepted to the ASSETS
            conference in Oct 2022.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Sidewalk Webpage: <a href="https://sidewalk-sea.cs.washington.edu" target="_blank">https://sidewalk-sea.cs.washington.edu</a></li>
            <li>Sidewalk Webpage Code: <a href="https://github.com/ProjectSidewalk/SidewalkWebpage" target="_blank">https://github.com/ProjectSidewalk/SidewalkWebpage</a></li>
            <li>Sidewalk CV Code: <a href="https://github.com/michaelduan8/sidewalk-cv-2021" target="_blank">https://github.com/michaelduan8/sidewalk-cv-2021</a></li>
            <li>Publication: <a href="https://dl.acm.org/doi/10.1145/3517428.3550381" target="_blank">https://dl.acm.org/doi/10.1145/3517428.3550381</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Sidewalk Webpage Languages: PostgreSQL, Scala, JavaScript, HTML, CSS</li>
            <li>Sidewalk CV Languages: Python, Bash</li>
            <li>Street View API: Google Street View</li>
            <li>ML Library: PyTorch</li>
            <li>Util Libraries: NumPy, Pandas, Matplotlib</li>
            <li>Paper: LaTeX</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            Here's a screenshot of the Project Sidewalk webpage for crowdsourcing labels. I worked on many features
            including visualizing the users observed area in the bottom right corner that improved data quality by
            incentivizing users to look around.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/project_sidewalk/webpage.jpg">
              <div class="caption">
                What a user might see as they label sidewalks.
              </div>
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Publication</div>
          <div class="pdf-container">
            <a class="pdf" href="assets/project_sidewalk/paper.pdf" target="_blank">
              <img class="pdf-thumbnail" src="assets/project_sidewalk/paper_thumbnail.jpg">
              <img class="pdf-open" src="assets/icons/pdf-open.png">
            </a>
          </div>
        </div>
      </div>

      <div id="danzon" class="section">
        <div class="header">Danz√≥n No. 2</div>
        <div class="date">Jul 2019 - Aug 2021</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            I first played Danz√≥n No. 2 by Arturo M√°rquez in my high school orchestra and I immediately fell in love with
            the catchy melodies and energetic rhythms. Danz√≥n is a style of dance originating in Cuba and popularized
            in Mexico, and I felt compelled to arrange this piece because it is so fun to play and so that my friends
            and I could spread this type of music into the otherwise eurocentric world of classical music. Also, after
            years of pouring over this score, this is easily my most thought out (and also most difficult) arrangement.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Full Score</div>
          <div class="pdf-container">
            <a class="pdf" href="assets/danzon/score.pdf" target="_blank">
              <img class="pdf-thumbnail" src="assets/danzon/score_thumbnail.jpg">
              <img class="pdf-open" src="assets/icons/pdf-open.png">
            </a>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Notable Excerpts</div>
          <div class="text">
            Bars 1 - 19: The piece begins with the iconic clarinet theme in the first cello and the baseline/clave rhythm in the second cello.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/1.jpg">
            </div>
          </div>
          <div class="text">
            The first notoriously difficult section comes during the "Poco pi√π mosso" at bar 66. In the original score, the strings
            are in octaves playing the theme in the first cello part and the woodwinds are playing a very high rhythmic counter theme.
            I initially tried putting that counter theme in the second cello part, but it was too overpowering, so instead I decided
            to reinforce the first cello theme in the second cello but with open strings and harmonics interspersed, simulating the
            effect of the counter theme.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/2.jpg">
            </div>
          </div>
          <div class="text">
            The second notoriously difficult section, "Con fuoco", is also most people's favorite. Here, the two cellos trade off
            a catchy theme from the brass/woodwinds and an energetic counterpart from the rest of the strings. When played
            at tempo, it is super difficult to make the far and frequent shifts sound clean and to ensure the clarity of
            articulation in the eigth notes.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/3.jpg">
            </div>
          </div>
          <div class="text">
            Another part that's slightly awkward is the second cello part after the "Con fuoco" when I tried to capture the effect of an entire string
            orchestra plucking away.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/4.jpg">
            </div>
          </div>
          <div class="text">
            My favorite part of the entire piece is the tempo primo. After an energetic and dissonant build up, the music
            releases into an impactful recap; the second cello begins an epic double-stop section as the first theme returns
            in the first cello. The second cello part is just barely playeable.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/5.jpg">
            </div>
          </div>
          <div class="text">
            In my opinion, by far the hardest section is the return of the super high second theme in bar 198. It's just
            very exposed and you have to cleanly execute shifts in an awkward register. I decided to end the section with
            harmonics to mimic the color of a flute and clarinet.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/6.jpg">
            </div>
          </div>
          <div class="text">
            The end of the piece consists of a gradual 16 bar crescendo where instruments from the symphony join one at a time.
            I simulated this by not only including the crescendo itself, but also gradually climbing octaves and incorporating
            double-stops.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/danzon/7.jpg">
            </div>
          </div>
        </div>
      </div>

      <div id="cinema-paradiso" class="section">
        <div class="header">Cinema Paradiso</div>
        <div class="date">Aug 2020 - Feb 2021</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Cinema Paradiso by Giuseppe Tornatore is a movie set in a small Sicilian town and covers themes such as love,
            loss, and nostalgia. The soundtrack, by Ennio Morricone, is some of my favorite movie scoring ever, and so I
            had to arrange it for two cellos. I ended up picking out iconic themes from the soundtrack, transcribing
            them by ear while adding in my own artistic touch, and stitching everything together into a sort of theme and
            variations which I feel tells a compelling and cohesive story.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Full Score</div>
          <div class="pdf-container">
            <a class="pdf" href="assets/cinema_paradiso/score.pdf" target="_blank">
              <img class="pdf-thumbnail" src="assets/cinema_paradiso/score_thumbnail.jpg">
              <img class="pdf-open" src="assets/icons/pdf-open.png">
            </a>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Notable Excerpts</div>
          <div class="text">
            The piece opens with a b-flat major arpeggio and 16-th note ornaments that leads into the introductory theme
            that reminds me of a sunrise with birds chirping away.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/1.jpg">
            </div>
          </div>
          <div class="text">
            The famous love theme, tema d'amore, is first introduced in bar 33, the subject of the theme and variations. I started with
            a simple pizzicato part in the second cello outlining the chords. This theme gets repeated 4 times in a row,
            two at a lower octave and two at a higher octave, each increasing in dynamics and complexity.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/2.jpg">
            </div>
          </div>
          <div class="text">
            In bar 72, we take a break from the love theme and introduce the "Infanzia" theme, symbolizing young/naive love. The
            two cellos trade off a simple theme with playful pizzicato.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/3.jpg">
            </div>
          </div>
          <div class="text">
            In the movie, the infanzia theme is often immediately followed by the "Maturit√†" theme, which features a rich
            melody played in the deeper register of the cello. The legato symbolizes rounded out wisdom and the two cellos
            playing in the similar octave symbolize the union of the two individualze's values (as opposed to the contrasting
            parts in the "Infanzia" theme). 
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/4.jpg">
            </div>
          </div>
          <div class="text">
            "Cinema in Fiamme" is a theme that plays only once in the entire movie right before disaster strikes. To make
            it especially climactic, I decided to double the theme across both parts, with an alternating arppegiated motif
            for added emphasis.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/5.jpg">
            </div>
          </div>
          <div class="text">
            Following the aftermath of the disaster, the love theme returns again in bar 157. Although this time,
            the accompaniment is a heartwrenching counter-melody with swirling chromaticism and becomes quite difficult
            as I try to capture multiple voices into a single part. Like before, the love theme repeats several more
            times, each increasing in intensity and grandeur. 
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/6.jpg">
            </div>
          </div>
          <div class="text">
            In my opinion, the hardest part by far is the first cello accompaniment of the penultimate love theme. No need
            to explain, just try playing it.
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/7.jpg">
            </div>
          </div>
          <div class="text">
            The piece reaches a rather grand resolution in bar 205 which easily sounds like it could be the end of the piece.
            However, I decided to add one last theme, "Ripensandola", which roughly translates to "Thinking About Her Again."
            The theme is a soft, broken version of the love theme, where each chord swells like a breath. My hope was to capture
            the nostalgic and cathartic reflections of one who's lover has passed away. 
          </div>
          <div class="image-container">
            <div class="image" style="width: 80%;">
              <img width="100%" src="assets/cinema_paradiso/8.jpg">
            </div>
          </div>
        </div>
      </div>

      <div id="cello" class="section">
        <div class="header">Cello</div>
        <div class="date">Nov 2005 - Present</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Here are some random videos of me playing cello with friends.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Some Improv</div>
          <div class="text">
            04/08/2023<br>
            Guitar: Arjun Srivastava<br>
            Cello: Sho Kiami<br>
            Keyboard: Pranav Bhagavatula<br>
            Arjun, Pranav, and I like to hold jam sessions every once in a while and here is a clip from one of those days.
            The result was some e-minor bossa nova type vibe.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/d406VDctxPE" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/improv_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Chopin - Cello Sonata, III. Largo</div>
          <div class="text">
            10/13/2022<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            Michael and I have been working on the Chopin Cello Sonata for some time now, and the third movement has always
            been a favorite due to its simplicity and beauty.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/d406VDctxPE" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/chopin_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Rachmaninoff - Cello Sonata, III. Andante (Arr. Sho Kiami)</div>
          <div class="text">
            12/20/2021<br>
            Cello 1: Sho Kiami<br>
            Cello 2: Yuta Kiami<br>
            Yuta had been working on the Rachmaninoff Cello Sonata and asked if I could arrange the piano part for cello and
            play it with him at a music night hosted by some friends. I thought the arrangement actually turned out quite
            well considering the fact that the piano part is notoriously complex.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/VcukGP_2XTY" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/rachmaninoff_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Arnesen - Magnificat</div>
          <div class="text">
            12/12/2021<br>
            University Presbyterian Church Choir<br>
            Various Musicians from Seattle<br>
            My old cello teacher, Rajan Krishnaswami, invited me to play this professional gig with him so I had to pull
            through. The performance was rather long and I wanted to highlight a piece called Magnificat written in 2010 by
            Norwegian composer Kim Andr√© Arnesen. This piece has easily some of the most beautiful harmonies I've ever heard
            and I especially love the final movement "Gloria Patri" starting at 54:18.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/MLoWVUZ3JVE?start=1372&end=3743" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/magnificat_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Bloch - From Jewish Life, I. Prayer</div>
          <div class="text">
            10/12/2021<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            This piece is inspired by prayers sung in Ashkenazi synagogues. It holds a special place in my heart as it is
            haungtingly gorgeous and sounds very human. Also, I think it works so well on the cello.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/JXZTA46R1Nk" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/prayer_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Piazzolla - Le Grand Tango</div>
          <div class="text">
            9/21/2020<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            I really really love Argentine tango and so I had to share this piece with Michael. This was actually our first
            time playing together and it led to many more years of music together.
          </div>
          <div class="youtube-container">
            <div id="https://www.youtube.com/embed/duuRF5fG5sM" class="youtube">
              <img class="youtube-thumbnail" src="assets/cello/piazzolla_thumbnail.jpg">
              <img class="youtube-play" src="assets/icons/youtube-play.png">
            </div>
          </div>
        </div>
      </div>

      <div id="contact" class="section">
        <div class="header">Contact Me</div>
        <div class="date"></div>
        <div class="subsection">
          <ul>
            <li>
              <i class="fa fa-envelope"></i>
              <a href="mailto:kiami.sho@gmail.com">kiami.sho@gmail.com</a>
            </li>
            <li>
              <i class="fa fa-linkedin-square"></i>
              <a href="https://linkedin.com/in/shokiami">linkedin.com/in/shokiami</a>
            </li>
            <li>
              <i class="fa fa-github"></i>
              <a href="https://github.com/shokiami">github.com/shokiami</a>
            </li>
          </ul>
        </div>
      </div>

      <div id="footer">¬© 2023 Shosuke C. Kiami</div>
    </div>
    <div id="mandelbrot-container"></div>
    <script src="main.js"></script>
  </body>
</html>
