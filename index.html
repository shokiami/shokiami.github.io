<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Sho Kiami</title>
    <link href="https://fonts.googleapis.com/css2?family=Italiana&family=Raleway:wght@100&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href='https://fonts.googleapis.com/css?family=Anaheim' rel='stylesheet'>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div id="home">
      <div id="title-container">
        <div id="title">Hi, I'm Sho</div>
        <div id="subtitle">Engineer, Math Enthusiast, Cellist</div>
      </div>
    </div>

    <div id="navbar">
      <a id="navbar-title" href="">Shosuke Kiami</a>
      <ul id="section-menu">
        <li><a href="#home">Home</a></li>
        <li><a href="#about">About</a></li>
        <li>
          <a href="#projects">Projects</a>
          <div id="project-dropdown" onclick="toggleDropdown(this)"><i class="dropdown-arrow"></i></div>
        </li>
        <ul id="project-menu" class="dropdown-menu">
          <li><a href="#dancetime">DanceTime</a></li>
          <li><a href="#alphafour">AlphaFour</a></li>
          <li><a href="#driverless-software">Driverless Software</a></li>
          <li><a href="#genaug">GenAug</a></li>
          <li><a href="#geoknowr">GeoKnowr</a></li>
          <li><a href="#frijma">Frijma</a></li>
          <li><a href="#project-sidewalk">Project Sidewalk</a></li>
          <li><a href="#danzon">Danzón No. 2</a></li>
          <li><a href="#cinema-paradiso">Cinema Paradiso</a></li>
          <li><a href="#cello">Cello</a></li>
        </ul>
        <li><a href="assets/shokiami_resume.pdf" target="_blank">Resume</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>

    <div id="main">
      <div id="about" class="section">
        <div class="header">About Me</div>
        <div class="date"></div>
        <div class="subsection">
          <img id="head-shot" width="200px" src="assets/sho.png">
          <div class="text">
            I am a student at the University of Washington passionate about mechanical engineering, computer science,
            mathematics, and cello.
          </div>
          <div class="text">
            I admit I have not taken the most orthodox path through undergrad. I began by studying CS because I was really
            into programming during high school and was working on all sorts of personal projects, but after interning at
            companies like Microsoft and Apple, I realized that software industry was not for me. I thought that maybe
            research would be more exciting, so I onboarded a second major in math early on and worked in labs across
            fields like computation biology, computer vision, and deep robotic learning.
          </div>
          <div class="text">
            However, just this past year, I was reminded of my childhood interest in mechanical engineering, and after having
            a blast taking physics courses, 3-D modeling in CAD, and manufacturing parts on the mill and lathe in the
            machine shop, I decided to pivot into engineering and onboard my third major. Today, I continue to further my
            passion for ME through my work as suspension engineer on UW Formula Motorsports and robotics researcher
            in the UW WEIRD lab.
          </div>
          <div class="text">
            Outside of school, my main hobby is playing the cello. I started when I was four years old and still play avidly
            today. Otherwise, I also enjoy playing other instruments (piano and guitar), music composition, calisthenics,
            skiing, drawing, and cooking.
          </div>
        </div>
      </div>
      
      <div id="projects" class="section">
        <div class="header">Projects</div>
        <div class="date"></div>
        <div class="subsection">
          <div id="project-list">
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Driverless Steering</div>
                <div class="project-date">Jul 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail in-progress" src="assets/driverless_steering/thumbnail.png">
                </div>
                <div class="project-description">
                  Design and manufacturing of driverless steering assembly and gearbox.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Drawing Robot</div>
                <div class="project-date">Aug 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail" src="assets/drawing_robot/thumbnail.png">
                </div>
                <div class="project-description">
                  Design and manufacturing of a robotic arm that can draw any image of choice.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a class="in-progress">
                <div class="project-title">Grasping in Clutter</div>
                <div class="project-date">Mar 2023 - Present</div>
                <div class="project-thumbnail-container">
                  <div class="in-progress-text">In Progress</div>
                  <img class="project-thumbnail" src="assets/grasping_in_clutter/thumbnail.png">
                </div>
                <div class="project-description">
                   RL Algorithms for teaching a robotic arm + hand to grasp objects in clutter.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#dancetime">
                <div class="project-title">DanceTime</div>
                <div class="project-date">May 2021 - Jul 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/dancetime/thumbnail.png">
                </div>
                <div class="project-description">
                  A multiplayer dance-based rhythm game inspired by Just Dance and FaceTime.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#alphafour">
                <div class="project-title">AlphaFour</div>
                <div class="project-date">Jun 2022 - Jul 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/alphafour/thumbnail.png">
                </div>
                <div class="project-description">
                  An AI that learns to play Connect 4 from scratch via self-play deep RL.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#driverless-software">
                <div class="project-title">Driverless Software</div>
                <div class="project-date">Jan 2023 - May 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/driverless_software/thumbnail.png">
                </div>
                <div class="project-description">
                  Control and planning algorithms for a driverless formula race car.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#genaug">
                <div class="project-title">GenAug</div>
                <div class="project-date">Jan 2023 - Mar 2023</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/genaug/thumbnail.png">
                </div>
                <div class="project-description">
                  Training a robot to perform pick-place tasks with imitation learning and generative models.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#geoknowr">
                <div class="project-title">GeoKnowr</div>
                <div class="project-date">Nov 2022 - Dec 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/geoknowr/thumbnail.png">
                </div>
                <div class="project-description">
                  Data collection, training, and evaluation pipeline for a light-weight GeoGuessr AI.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#frijma">
                <div class="project-title">Frijma</div>
                <div class="project-date">Oct 2022 - Oct 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/frijma/thumbnail.png">
                </div>
                <div class="project-description">
                  A web app where you can scan receipts and keep track of expiration dates.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#project-sidewalk">
                <div class="project-title">Project Sidewalk</div>
                <div class="project-date">Jun 2020 - Jun 2022</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/project_sidewalk/thumbnail.png">
                </div>
                <div class="project-description">
                  A data crowdsourcing and computer vision pipeline for sidewalk accessibility evaluation.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#danzon">
                <div class="project-title">Danzón No. 2</div>
                <div class="project-date">Jul 2019 - Aug 2021</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/danzon/thumbnail.png">
                </div>
                <div class="project-description">
                  An arrangement of Arturo Márquez's Danzón No. 2 for two cellos.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#cinema-paradiso">
                <div class="project-title">Cinema Paradiso</div>
                <div class="project-date">Aug 2020 - Feb 2021</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/cinema_paradiso/thumbnail.png">
                </div>
                <div class="project-description">
                  Variations on Ennio Morricone's Cinema Paradiso for two cellos.
                </div>
              </a>
            </div>
            <div class="project-container">
              <a href="#cello">
                <div class="project-title">Cello</div>
                <div class="project-date">Nov 2005 - Present</div>
                <div class="project-thumbnail-container">
                  <img class="project-thumbnail" src="assets/cello/thumbnail.png">
                </div>
                <div class="project-description">
                  Some random videos of me playing cello with friends.
                </div>
              </a>
            </div>
          </div>
        </div>
      </div>

      <div id="dancetime" class="section">
        <div class="header">DanceTime</div>
        <div class="date">May 2021 - Jul 2023</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            DanceTime is a multiplayer dance-based rhythm game inspired by Just Dance and FaceTime. The premise is very
            simple: each player must try to follow the dance moves of the avatar as closely as possible, and the closer
            you are, the more points you get.
            This is one of my most technical projects as it features a custom pose estimation library that is so
            optimized that it can run smoothly on any laptop and an original regression-based numerical scoring algorithm.
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/dancetime/dancing.mp4" type="video/mp4"/>
            </video>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Code: <a href="https://github.com/shokiami/DanceTime" target="_blank">https://github.com/shokiami/DanceTime</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Language: C++</li>
            <li>CV Library: OpenCV</li>
            <li>ML Library: MediaPipe, TensorFlow Lite</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">System Overview</div>
          <div class="text">
            DanceTime's control flow is difficult to summarize due to its many complicated algorithms and abundance of parallelism.
            However, here is my best attempt:
          </div>
          <div class="image-container">
            <img width="80%" src="assets/dancetime/flow.png">
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Algorithms</div>
          <div class="text">
            One algorithm I wanted to highlight was the scoring algorithm. This algorithm took me nearly an entire year
            to develop, namely because the problem was so non-trivial:
          </div>
          <div class="text">
            Define a pose to be a set of (x, y) coordinates for various key joints/body parts. Given a constant stream
            of noisy pose readings, how can we arrive at a score which captures how similarly the two players danced?
          </div>
          <div class="text">
            There were three main challenges which made this problem difficult:
          </div>
          <ul class="list">
            <li>Invariance: translation/scaling should not affect scoring.</li>
            <li>Noise: the pose data can be very jittery/sporadic.</li>
            <li>Timing offset: scoring cannot fixate on current poses and must account for timing offsets.</li>
          </ul>
          <div class="text">
            Invariance was the easiest problem to address. I tried various strategies such as comparing joint velocities and
            joint angles, but both of these failed due to the noise. What worked best was translating/scaling each pose
            such that the torso height had unit length and was centered at the origin.
          </div>
          <div class="text">
            Noise was the hardest one to combat. For example, examining the x coordinate of the left wrist might yield data
            that looks like the following:
          </div>
          <div class="image-container">
            <img width="80%" src="assets/dancetime/1.png">
          </div>
          <div class="text">
            The first natural step was to use a moving average, but this ended up either not making a significant enough
            impact or over-dampening the gesture trajectory shape.
          </div>
          <div class="text">
            So instead, I came up with a two part solution. The first part is a conditional moving average which only
            averages if a current point is further from its neighbors than they are to each other. This works because
            it still preserves a lot of the gesture trajectory shape.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/dancetime/2.png">
          </div>
          <div class="text">
            The second part is using regression to find the polynomial of best fit for the data. The intuition is that this would help
            capture the player's overall gesture and significantly reduce the affect of any remaining noise in our data.
            After lots of experimentation, I found that a polynomial degree of 3 provided the best results without overfitting.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/dancetime/3.png">
          </div>
          <div class="text">
            Using polynomial regression actually serves a second purpose which is that it makes addressing the timing offset issue
            more straight forward as we are now operating in continuous space. To find the timing offset between the player and the avatar,
            we can simply take their polynomials and shift them around to find what horizontal offset minimizes the error between them.
            I ended up using maximum error instead of mean error for my error criterion since it was more reliably minimized when
            the functions were horizontally aligned. In the following visual, the red and blue functions are vertical translations
            of each other and the green function is the mean error as a function of offset and the orange function is the max
            error as a function of offset. We see that the max error is minimized at offset 0 which is desired.
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/dancetime/4.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="text">
            Finally, we can take the error and offset and feed them into some activation function such as a sigmoid
            to get a similarity value between 0 and 1.
          </div>
          <div class="text">
            Here is the full pseudocode for the entire scoring algorithm:
          </div>
          <div class="algo">
            function remove_outliers(poses):
            <div class="tabbed">
              for pose in poses:
              <div class="tabbed">
                for body_part in pose:
                <div class="tabbed">
                  prev_to_curr = dist(prev_body_part, body_part)<br>
                  curr_to_next = dist(body_part, next_body_part)<br>
                  pev_to_next = dist(prev_body_part, next_body_part)<br>
                  if prev_to_next < prev_to_curr or prev_to_next < curr_to_next:
                  <div class="tabbed">
                    body_part = (prev_body_part + next_body_part) / 2
                  </div>
                </div>
              </div>
            </div>
          </div>
          <div class="algo">
            function standardize(poses):
            <div class="tabbed">
              for pose in poses:
              <div class="tabbed">
                left_shoulder = pose[left_shoulder]<br>
                right_shoulder = pose[right_shoulder]<br>
                left_hip = pose[left_hip]<br>
                right_hip = pose[right_hip]<br>
                torso_center = (left_shoulder + left_hip + right_shoulder + right_hip) / 4.0<br>
                left_torso_length = dist(left_shoulder, left_hip)<br>
                right_torso_length = dist(right_shoulder, right hip)<br>
                torso_length = (left_torso_length + right_torso_length) / 2<br>
                for body_part in pose:
                <div class="tabbed">
                  body_part = (body_part - torso_center) / torso_length
                </div>
              </div>
            </div>
          </div>
          <div class="algo">
            function poly_regression(poses):
            <div class="tabbed">
              polys = {}<br>
              for body_part in body_parts:
              <div class="tabbed">
                A = matrix(poses.length, POLY_DEGREE + 1)<br>
                b = vector(poses.length)<br>
                for i from 0 to poses.length:
                <div class="tabbed">
                  A[i] = [1, i, i^2, ..., i^POLY_DEGREE]<br>
                  b[i] = poses[i][body_part]
                </div>
                P = A * (A^T * A)^-1 * A^T<br>
                proj_b = P * b<br>
                poly_coeffs = A^-1 * proj_b<br>
                polys[body_part] = poly_coeffs
              </div>
              return polys
            </div>
          </div>
          <div class="algo">
            function max_error(player_polys, avatar_polys):
            <div class="tabbed">
              max_error = -infinity<br>
              for body_part in body_parts:
              <div class="tabbed">
                for t from T_START to T_END with T_STEP:
                <div class="tabbed">
                  f = player_polys[body_part]<br>
                  g = avatar_polys[body_part]<br>
                  error = (f(t) - g(t))^2<br>
                  if error > max_error:
                  <div class="tabbed">
                    max_error = error
                  </div>
                </div>
              </div>
              return max_error
            </div>
          </div>
          <div class="algo">
            function score(player_poses, avatar_poses):
            <div class="tabbed">
              remove_outliers(player_poses)<br>
              remove_outliers(player_poses)<br>
              standardize(player_poses)<br>
              standardize(avatar_poses)<br>
              player_polys = poly_regression(player_poses)<br>
              avatar_polys = poly_regression(avatar_poses)<br>
              min_error = infinity<br>
              for t from T_MIN to T_MAX with T_STEP:
              <div class="tabbed">
                error = max_error(player_polys.translate(t), avatar_polys)<br>
                if error < min_error:
                <div class="tabbed">
                  min_error = error<br>
                  offset = |t|
                </div>
              </div>
              score = sigmoid(min_error + OFFSET_COST * offset)<br>
              return score
            </div>
          </div>
        </div>
      </div>

      <div id="alphafour" class="section">
        <div class="header">AlphaFour</div>
        <div class="date">Jun 2022 - Jul 2023</div>
        <div class="text">
          Sed risus pretium quam vulputate dignissim suspendisse. Sem fringilla ut morbi tincidunt augue interdum. Orci dapibus ultrices in iaculis nunc sed. Vitae justo eget magna fermentum iaculis eu non diam phasellus. Quam id leo in vitae turpis massa sed. Commodo viverra maecenas accumsan lacus vel facilisis volutpat est velit. Vitae congue eu consequat ac felis donec et odio pellentesque. Aliquam vestibulum morbi blandit cursus risus. Enim eu turpis egestas pretium aenean pharetra magna. Libero volutpat sed cras ornare arcu dui vivamus. Velit scelerisque in dictum non consectetur a erat. Sed cras ornare arcu dui vivamus arcu felis bibendum ut. Purus faucibus ornare suspendisse sed nisi lacus sed viverra tellus. Senectus et netus et malesuada. Enim praesent elementum facilisis leo vel fringilla est ullamcorper eget. Sit amet facilisis magna etiam tempor. <br><br>
          Erat velit scelerisque in dictum non consectetur. At lectus urna duis convallis convallis tellus id. Ut pharetra sit amet aliquam id diam. Lectus sit amet est placerat. Consectetur adipiscing elit duis tristique sollicitudin nibh sit amet. Vitae congue eu consequat ac felis. Egestas integer eget aliquet nibh praesent tristique. Ut eu sem integer vitae justo eget magna fermentum. Eget duis at tellus at urna condimentum mattis. Sit amet luctus venenatis lectus magna fringilla. Enim diam vulputate ut pharetra sit amet aliquam id diam. Nisl nunc mi ipsum faucibus vitae aliquet. Fermentum dui faucibus in ornare quam viverra. Curabitur gravida arcu ac tortor. Id consectetur purus ut faucibus. <br><br>
          Adipiscing elit ut aliquam purus sit amet luctus venenatis lectus. Ipsum a arcu cursus vitae congue mauris rhoncus. Quam viverra orci sagittis eu volutpat odio. Imperdiet sed euismod nisi porta lorem mollis aliquam ut. Eget dolor morbi non arcu risus quis varius quam. Blandit libero volutpat sed cras ornare arcu dui. Metus vulputate eu scelerisque felis imperdiet. Eget egestas purus viverra accumsan in nisl nisi scelerisque. Rhoncus mattis rhoncus urna neque viverra. Arcu non sodales neque sodales ut. Sed ullamcorper morbi tincidunt ornare massa. Hac habitasse platea dictumst vestibulum rhoncus est pellentesque elit ullamcorper. Odio euismod lacinia at quis risus sed. Nunc vel risus commodo viverra. Sed euismod nisi porta lorem mollis aliquam ut. Lobortis scelerisque fermentum dui faucibus in. Ultricies integer quis auctor elit sed vulputate mi sit. Id cursus metus aliquam eleifend mi in. <br><br>
          Adipiscing elit ut aliquam purus sit. Bibendum est ultricies integer quis auctor. A erat nam at lectus urna duis convallis convallis. Quam nulla porttitor massa id neque. Pretium lectus quam id leo in. Sit amet mauris commodo quis. Tristique nulla aliquet enim tortor. Cursus turpis massa tincidunt dui ut. Praesent elementum facilisis leo vel fringilla. Vestibulum lorem sed risus ultricies tristique nulla aliquet. <br><br>
          Interdum posuere lorem ipsum dolor sit amet consectetur. Lobortis elementum nibh tellus molestie nunc non blandit. Augue eget arcu dictum varius. Pulvinar sapien et ligula ullamcorper. Egestas sed tempus urna et pharetra pharetra. Consectetur libero id faucibus nisl tincidunt eget nullam non nisi. Orci phasellus egestas tellus rutrum. Felis eget nunc lobortis mattis aliquam faucibus purus in massa. Ut faucibus pulvinar elementum integer enim neque volutpat ac. Tortor id aliquet lectus proin nibh nisl condimentum id venenatis. Ac turpis egestas maecenas pharetra convallis posuere morbi. Id interdum velit laoreet id donec ultrices tincidunt arcu non. Nulla at volutpat diam ut venenatis tellus in. Nibh mauris cursus mattis molestie a iaculis at erat. At ultrices mi tempus imperdiet nulla malesuada pellentesque elit eget. Mattis enim ut tellus elementum sagittis vitae et leo duis. Turpis egestas pretium aenean pharetra magna ac placerat vestibulum lectus. Auctor eu augue ut lectus arcu bibendum at varius vel. Egestas erat imperdiet sed euismod nisi porta. Justo laoreet sit amet cursus. <br><br>
          Cursus risus at ultrices mi tempus imperdiet nulla malesuada pellentesque. Gravida in fermentum et sollicitudin ac. Diam maecenas ultricies mi eget. Id donec ultrices tincidunt arcu non sodales neque sodales. Curabitur vitae nunc sed velit dignissim sodales ut. Lacus viverra vitae congue eu. Lacus vel facilisis volutpat est velit egestas dui. Facilisi nullam vehicula ipsum a arcu cursus vitae congue. Enim nunc faucibus a pellentesque sit amet porttitor eget dolor. Imperdiet sed euismod nisi porta lorem mollis aliquam. Ultricies leo integer malesuada nunc. Viverra vitae congue eu consequat ac felis donec et odio. Non enim praesent elementum facilisis leo vel fringilla est. Enim eu turpis egestas pretium aenean pharetra magna. Cursus mattis molestie a iaculis at erat pellentesque adipiscing commodo. Augue mauris augue neque gravida in. Non curabitur gravida arcu ac tortor dignissim convallis aenean et. Dictum sit amet justo donec enim diam vulputate ut. Justo eget magna fermentum iaculis eu non. Ac tortor vitae purus faucibus. <br><br>
          Est sit amet facilisis magna etiam. Tristique et egestas quis ipsum suspendisse ultrices gravida. Senectus et netus et malesuada fames. Nec feugiat in fermentum posuere. Et molestie ac feugiat sed lectus vestibulum mattis ullamcorper velit. Fames ac turpis egestas integer eget aliquet nibh praesent tristique. Faucibus nisl tincidunt eget nullam non. Adipiscing commodo elit at imperdiet dui accumsan sit amet nulla. Turpis nunc eget lorem dolor sed viverra ipsum nunc. Nunc faucibus a pellentesque sit amet porttitor. Neque ornare aenean euismod elementum nisi quis eleifend. Nunc sed id semper risus in hendrerit gravida rutrum quisque. Consequat semper viverra nam libero justo. <br><br>
          In nisl nisi scelerisque eu ultrices vitae. Tellus at urna condimentum mattis. Tortor pretium viverra suspendisse potenti nullam ac tortor vitae. Quisque sagittis purus sit amet volutpat consequat mauris nunc congue. Purus ut faucibus pulvinar elementum integer enim. Vitae proin sagittis nisl rhoncus mattis rhoncus urna neque. Ridiculus mus mauris vitae ultricies leo integer malesuada nunc vel. Pellentesque habitant morbi tristique senectus et. Dictumst vestibulum rhoncus est pellentesque. Ac tortor dignissim convallis aenean et tortor.
        </div>
      </div>

      <div id="driverless-software" class="section">
        <div class="header">Driverless Software</div>
        <div class="date">Jan 2023 - May 2023</div>
        <div class="text">
          Sed risus pretium quam vulputate dignissim suspendisse. Sem fringilla ut morbi tincidunt augue interdum. Orci dapibus ultrices in iaculis nunc sed. Vitae justo eget magna fermentum iaculis eu non diam phasellus. Quam id leo in vitae turpis massa sed. Commodo viverra maecenas accumsan lacus vel facilisis volutpat est velit. Vitae congue eu consequat ac felis donec et odio pellentesque. Aliquam vestibulum morbi blandit cursus risus. Enim eu turpis egestas pretium aenean pharetra magna. Libero volutpat sed cras ornare arcu dui vivamus. Velit scelerisque in dictum non consectetur a erat. Sed cras ornare arcu dui vivamus arcu felis bibendum ut. Purus faucibus ornare suspendisse sed nisi lacus sed viverra tellus. Senectus et netus et malesuada. Enim praesent elementum facilisis leo vel fringilla est ullamcorper eget. Sit amet facilisis magna etiam tempor. <br><br>
          Erat velit scelerisque in dictum non consectetur. At lectus urna duis convallis convallis tellus id. Ut pharetra sit amet aliquam id diam. Lectus sit amet est placerat. Consectetur adipiscing elit duis tristique sollicitudin nibh sit amet. Vitae congue eu consequat ac felis. Egestas integer eget aliquet nibh praesent tristique. Ut eu sem integer vitae justo eget magna fermentum. Eget duis at tellus at urna condimentum mattis. Sit amet luctus venenatis lectus magna fringilla. Enim diam vulputate ut pharetra sit amet aliquam id diam. Nisl nunc mi ipsum faucibus vitae aliquet. Fermentum dui faucibus in ornare quam viverra. Curabitur gravida arcu ac tortor. Id consectetur purus ut faucibus. <br><br>
          Adipiscing elit ut aliquam purus sit amet luctus venenatis lectus. Ipsum a arcu cursus vitae congue mauris rhoncus. Quam viverra orci sagittis eu volutpat odio. Imperdiet sed euismod nisi porta lorem mollis aliquam ut. Eget dolor morbi non arcu risus quis varius quam. Blandit libero volutpat sed cras ornare arcu dui. Metus vulputate eu scelerisque felis imperdiet. Eget egestas purus viverra accumsan in nisl nisi scelerisque. Rhoncus mattis rhoncus urna neque viverra. Arcu non sodales neque sodales ut. Sed ullamcorper morbi tincidunt ornare massa. Hac habitasse platea dictumst vestibulum rhoncus est pellentesque elit ullamcorper. Odio euismod lacinia at quis risus sed. Nunc vel risus commodo viverra. Sed euismod nisi porta lorem mollis aliquam ut. Lobortis scelerisque fermentum dui faucibus in. Ultricies integer quis auctor elit sed vulputate mi sit. Id cursus metus aliquam eleifend mi in. <br><br>
          Adipiscing elit ut aliquam purus sit. Bibendum est ultricies integer quis auctor. A erat nam at lectus urna duis convallis convallis. Quam nulla porttitor massa id neque. Pretium lectus quam id leo in. Sit amet mauris commodo quis. Tristique nulla aliquet enim tortor. Cursus turpis massa tincidunt dui ut. Praesent elementum facilisis leo vel fringilla. Vestibulum lorem sed risus ultricies tristique nulla aliquet. <br><br>
          Interdum posuere lorem ipsum dolor sit amet consectetur. Lobortis elementum nibh tellus molestie nunc non blandit. Augue eget arcu dictum varius. Pulvinar sapien et ligula ullamcorper. Egestas sed tempus urna et pharetra pharetra. Consectetur libero id faucibus nisl tincidunt eget nullam non nisi. Orci phasellus egestas tellus rutrum. Felis eget nunc lobortis mattis aliquam faucibus purus in massa. Ut faucibus pulvinar elementum integer enim neque volutpat ac. Tortor id aliquet lectus proin nibh nisl condimentum id venenatis. Ac turpis egestas maecenas pharetra convallis posuere morbi. Id interdum velit laoreet id donec ultrices tincidunt arcu non. Nulla at volutpat diam ut venenatis tellus in. Nibh mauris cursus mattis molestie a iaculis at erat. At ultrices mi tempus imperdiet nulla malesuada pellentesque elit eget. Mattis enim ut tellus elementum sagittis vitae et leo duis. Turpis egestas pretium aenean pharetra magna ac placerat vestibulum lectus. Auctor eu augue ut lectus arcu bibendum at varius vel. Egestas erat imperdiet sed euismod nisi porta. Justo laoreet sit amet cursus. <br><br>
          Cursus risus at ultrices mi tempus imperdiet nulla malesuada pellentesque. Gravida in fermentum et sollicitudin ac. Diam maecenas ultricies mi eget. Id donec ultrices tincidunt arcu non sodales neque sodales. Curabitur vitae nunc sed velit dignissim sodales ut. Lacus viverra vitae congue eu. Lacus vel facilisis volutpat est velit egestas dui. Facilisi nullam vehicula ipsum a arcu cursus vitae congue. Enim nunc faucibus a pellentesque sit amet porttitor eget dolor. Imperdiet sed euismod nisi porta lorem mollis aliquam. Ultricies leo integer malesuada nunc. Viverra vitae congue eu consequat ac felis donec et odio. Non enim praesent elementum facilisis leo vel fringilla est. Enim eu turpis egestas pretium aenean pharetra magna. Cursus mattis molestie a iaculis at erat pellentesque adipiscing commodo. Augue mauris augue neque gravida in. Non curabitur gravida arcu ac tortor dignissim convallis aenean et. Dictum sit amet justo donec enim diam vulputate ut. Justo eget magna fermentum iaculis eu non. Ac tortor vitae purus faucibus. <br><br>
          Est sit amet facilisis magna etiam. Tristique et egestas quis ipsum suspendisse ultrices gravida. Senectus et netus et malesuada fames. Nec feugiat in fermentum posuere. Et molestie ac feugiat sed lectus vestibulum mattis ullamcorper velit. Fames ac turpis egestas integer eget aliquet nibh praesent tristique. Faucibus nisl tincidunt eget nullam non. Adipiscing commodo elit at imperdiet dui accumsan sit amet nulla. Turpis nunc eget lorem dolor sed viverra ipsum nunc. Nunc faucibus a pellentesque sit amet porttitor. Neque ornare aenean euismod elementum nisi quis eleifend. Nunc sed id semper risus in hendrerit gravida rutrum quisque. Consequat semper viverra nam libero justo. <br><br>
          In nisl nisi scelerisque eu ultrices vitae. Tellus at urna condimentum mattis. Tortor pretium viverra suspendisse potenti nullam ac tortor vitae. Quisque sagittis purus sit amet volutpat consequat mauris nunc congue. Purus ut faucibus pulvinar elementum integer enim. Vitae proin sagittis nisl rhoncus mattis rhoncus urna neque. Ridiculus mus mauris vitae ultricies leo integer malesuada nunc vel. Pellentesque habitant morbi tristique senectus et. Dictumst vestibulum rhoncus est pellentesque. Ac tortor dignissim convallis aenean et tortor.
        </div>
      </div>
      
      <div id="genaug" class="section">
        <div class="header">GenAug</div>
        <div class="date">Jan 2023 - Mar 2023</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Suppose you want a robotic arm that when told "put the cup on the coaster" or "put the small box in the larger box"
            is able to perform the task first try. While imitation learning provides one method of training a robot to
            perform manipulation tasks, since collecting real-world examples is expensive, the training data will likely
            contain limited objects/scenes, preventing the robot from generalizing to novel scenarios.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/genaug/pipeline.png">
          </div>
          <div class="text">
            GenAug was a solution proposed by PhD student Zoey Chen (a colleague from the UW WEIRD Lab) who asked me to
            join her on the project. The idea behind GenAug is to use generative models such as stable diffusion
            to augment the training data (replace the pick object, replace the place object, alter the scene, add distractors, etc.).
            Our hope was that the large amounts of web-scraped data these generative models were trained on would serve
            as a prior and thus provide more semantically meaningful augmentation than classical data augmentation
            techniques (noise injection, transformations, etc.).
            Sure enough, in our real-world experiments, we found that GenAug improved our robot's zero-shot success rate
            by 40%, allowing our robot to perform general table-top manipulation tasks with minimal human demonstrations.
            Our results were published in a paper that was accepted to the Robotics Science and Systems conference in
            Jun 2023 and was a Best System Paper Finalist.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Website: <a href="https://genaug.github.io" target="_blank">https://genaug.github.io</a></li>
            <li>Code: <a href="https://github.com/genaug/genaug" target="_blank">https://github.com/genaug/genaug</a></li>
            <li>Paper: <a href="https://arxiv.org/abs/2302.06671" target="_blank">https://arxiv.org/abs/2302.06671</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Hardware: 6 DoF xArm5 w/ Vacuum Gripper, Intel RealSense Camera (D435i)</li>
            <li>Languages: Python, Bash</li>
            <li>Robotics Library: ROS</li>
            <li>Sim Library: PyBullet</li>
            <li>ML Library: PyTorch</li>
            <li>Paper: LaTeX</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            Our setup involves the xArm mounted to a table with a vacuum gripper and the depth camera pointing towards
            the table top (left-hand image).
            To collect human demonstrations, the user labels pick/place locations on a 2D top-down projection of the
            scene point cloud. These locations are mapped back to 3D coordinates using calibrated depth maps (right-hand gif).
          </div>
          <div class="image-container">
            <img width="45%" src="assets/genaug/setup.png">
            <video width="45%" autoplay loop muted>
              <source src="assets/genaug/datacollection.mp4" type="video/mp4"/>
            </video>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Data Augmentation</div>
          <div class="text">
            We used GenAug to augment our dataset in the following ways:
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/distractor.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/table.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/object.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/texture.mp4" type="video/mp4"/>
            </video>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Zero-Shot Deployment</div>
          <div class="text">
            After training our model on the augmented dataset, we test it on our robot on scenes it has never seen before.
            Here are some examples from our testing:
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/bowl2bowl.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/bowl2coaster.mp4" type="video/mp4"/>
            </video>
          </div>
          <div class="image-container">
            <video width="80%" autoplay loop muted>
              <source src="assets/genaug/box2basket.mp4" type="video/mp4"/>
            </video>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Video</div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/MxcmKKvdBhk?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Publication</div>
          <div class="pdf">
            <iframe height="830" width="600" src="assets/genaug/paper.pdf"></iframe>
          </div>
        </div>
      </div>

      <div id="geoknowr" class="section">
        <div class="header">GeoKnowr</div>
        <div class="date">Nov 2022 - Dec 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            <a href="https://www.geoguessr.com/" target="_blank">GeoGuessr</a>
            is a popular web game where users are thrown into random locations around the world in
            Google Street View and are challenged to place a marker on the world map to guess where they are in the world
            (the closer you guess, the more points you get). Here's an example image you might encounter:
          </div>
          <div class="image-container">
            <img width="80%" src="assets/geoknowr/geoguessr.png">
          </div>
          <div class="text">
            My friend Zach Chapman and I wanted to use deep learning to create a GeoGuessr AI that would be able to
            reliably guess the location of where such images were taken. Furthermore, GeoGuessr has several different modes,
            one of which is NMPZ (no moving-panning-zooming) which is notoriously the most difficult and thus the one we wanted to tackle.
            We created the entire data collection, training, and testing pipeline from scratch.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Code: <a href="https://github.com/shokiami/GeoKnowr" target="_blank">https://github.com/shokiami/GeoKnowr</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Language: Python, JavaScript, HTML, CSS</li>
            <li>Street View API: Google Street View</li>
            <li>ML Libraries: PyTorch, Scikit-learn</li>
            <li>Util Libraries: Pandas, Matplotlib, WebGL</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            Our data colelction pipeline could be broken up into the following steps:
          </div>
          <ol class="list">
            <li>Choose a random (latitude, longitude) coordinate.</li>
            <li>Use Google's API's to see if any Google Street View locations exist within a 10km search radius.</li>
            <li>If so, grab the metadata for that location and scrape the corresponding street view image at a random heading.</li>
            <li>Repeat steps 1-3 until we gather enough data.</li>
          </ol>
          <div class="text">
            Using this method, we downloaded a total of 32,000 images with resolution 480x360 from around the world.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Training</div>
          <div class="text">
            Initially, we framed this as a regression problem, with the goal of minimizing surface distance around the
            unit sphere because this is ultimately the criterion we are trying to minimize when playing GeoGuessr.
            However, the issue with this was that our model would learn to spam Greenland. This made sense because most
            of the Google's street view data is in the northern hemisphere and thus our model could achieve a decent
            score by average guessing.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/geoknowr/coverage.png">
          </div>
          <div class="text">
            To combat this issue, we reframed the problem as classification by dividing up the globe into numerous regions.
            The idea was that the model would classify an image into one of these regions and then guess the center of the region.
            This forced our model to commit more, as nearby regions are equally penalized as regions on the opposite side of the world.
            Another motivation behind this pivot was the recognition that humans also play GeoGuessr by region-guessing.
          </div>
          <div class="text">
            First we tried dividing up the world into a uniform grid, however, the majority of these classes had little to no
            examples being over water or in areas with low GSV coverage, so our model would learn to spam the majority class.
            We addressed this by cleverly using clustering algorithms to perform the class divisions for us, leading to more
            equal sized classes (and less data sparsity). Note how the clusters line up with Google's coverage.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/geoknowr/clusters.png">
          </div>
          <div class="text">
            Our final performance boost came from recognizing that we did not have enough data to adequately train a
            deep neural network from scratch, and so we used transfer learning on ResNet-18 pretrained on the ImageNet
            dataset. Now, our model no longer had to learn feature extraction and could instead focus on finding
            the relationship between the features provided by pretrained ResNet-18 and our classes.
          </div>
          <div class="text">
            Throughout this entire process, we also used an abundance of deep learning techniques such as learning rate
            annealing and weight decay.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Results</div>
          <div class="text">
            Here are our results after training for 5 hours:
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/loss.png">
            <img width="45%" src="assets/geoknowr/accuracy.png">
          </div>
          <div class="image-container">
            <img width="80%" src="assets/geoknowr/distances.png">
          </div>
          <ul class="list">
            <li>5th percentile: 361.33km (correct part of country)</li>
            <li>10th percentile: 520.11km (correct country)</li>
            <li>25th percentile: 980.21km (correct region)</li>
            <li>Median: 2839.96km (correct continent)</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Examples</div>
          <div class="text">
            Here are 10 example images and corresponding guesses from our model.
            The red marker represents the ground truth and the grey marker represents the AI's guess.
          </div>
          <div class="text">
            Eurajoki, Finland: 46.15km away<br>
            GT: (61.24206624516949, 21.49451874391871)<br>
            Guess: (60.866010738653614, 21.13157246788378)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/1a.png">
            <img width="45%" src="assets/geoknowr/1b.png">
          </div>
          <div class="text">
            Cedar Pocket, Australia: 766.68km away<br>
            GT: (-26.2016867183339, 152.7428709700448)<br>
            Guess: (-31.684634839922268, 147.96179641452864)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/2a.png">
            <img width="45%" src="assets/geoknowr/2b.png">
          </div>
          <div class="text">
            Ōdai, Japan: 554.07km away<br>
            GT: (34.29128958773475, 136.2255376621636)<br>
            Guess: (39.220061536212654, 137.1401260865559)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/3a.png">
            <img width="45%" src="assets/geoknowr/3b.png">
          </div>
          <div class="text">
            Pervomaiskii, Russia: 750.37km away<br>
            GT: (54.67348511884279, 54.76858543638147)<br>
            Guess: (57.3687329171972, 65.85774195636928)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/4a.png">
            <img width="45%" src="assets/geoknowr/4b.png">
          </div>
          <div class="text">
            Clavering Øer, Greenland: 3001.91km away<br>
            GT: (74.36102804428536, -20.31095398871028)<br>
            Guess: (62.88085149124142, -94.28640809358343)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/5a.png">
            <img width="45%" src="assets/geoknowr/5b.png">
          </div>
          <div class="text">
            Nuenen, Netherlands: 728.77km away<br>
            GT: (51.47712383096619, 5.568049157904403)<br>
            Guess: (46.52608328096249, -0.99022351617955)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/6a.png">
            <img width="45%" src="assets/geoknowr/6b.png">
          </div>
          <div class="text">
            Tanjung Mulia, Indonesia: 778.63km away<br>
            GT: (2.111117753198836, 100.2296566933782)<br>
            Guess: (9.086239024023117, 99.60871719478148)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/7a.png">
            <img width="45%" src="assets/geoknowr/7b.png">
          </div>
          <div class="text">
            Takper, Nigeria: 860.73km away<br>
            GT: (7.055152796196378, 8.483934407321177)<br>
            Guess: (9.65765106509962, 1.1147835438224805)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/8a.png">
            <img width="45%" src="assets/geoknowr/8b.png">
          </div>
          <div class="text">
            Colonia Río Escondido, México: 26.80km away<br>
            GT: (28.57000772521148, -100.6163712162074)<br>
            Guess: (28.465027052700034, -100.36940739027031)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/9a.png">
            <img width="45%" src="assets/geoknowr/9b.png">
          </div>
          <div class="text">
            Chipaya, Bolivia: 1133.61km away<br>
            GT: (-19.00475769083379, -68.10597816923791)<br>
            Guess: (-8.813989360376178, -68.40059804082549)
          </div>
          <div class="image-container">
            <img width="45%" src="assets/geoknowr/10a.png">
            <img width="45%" src="assets/geoknowr/10b.png">
          </div>
        </div>
      </div>

      <div id="frijma" class="section">
        <div class="header">Frijma</div>
        <div class="date">Oct 2022 - Oct 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Frijma is a web app that allows users to scan grocery receipts using their phone camera, keeps track of their
            expiration dates with easily digestible visuals, and also provides recipe inspiration for efficient meal
            planning—ultimately reducing food waste due to food items exceeding their expiration date.
          </div>
          <div class="text">
            Frijma was a submission to the 24-hour DubHacks'22 hackathon. My team consisted of me, Stefan Todoran,
            Nicholas Bradley, and Zach Chapman.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Frijma: <a href="https://todoran.dev/frijma" target="_blank">https://todoran.dev/frijma</a></li>
            <li>Code: <a href="https://github.com/StefanTodoran/frijma" target="_blank">https://github.com/StefanTodoran/frijma</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Languages: TypeScript, Javascript, HTML, CSS</li>
            <li>Food Dataset: <a href="https://www.fsis.usda.gov/shared/data/EN/" target="_blank">US Department of Agriculture</a></li>
            <li>Image to Text: Tesseract.js</li>
            <li>Recipe API: Edamam</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">System Overview</div>
          <div class="image-container">
            <img width="80%" src="assets/frijma/flow.png">
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Algorithms</div>
          <div class="text">
            Although I worked on the entire pipeline, the I focused on the parsing, search, and edit-distance
            algorithms. The runtime of the three combined algorithms is O(mn) where m is the number of characters in the receipt
            and n is the number of characters in the dataset (note that this is the optimal runtime).
            Here is the pseudocode for the three algorithms:
          </div>
          <div class="algo">
            function parse(receipt):
            <div class="tabbed">
              for line in receipt:
              <div class="tabbed">
                if line satisfies regex "*XX.XX":
                <div class="tabbed">
                  abbrv = line.remove(non-letters)<br>
                  if abbrv == "":
                  <div class="tabbed">
                    continue
                  </div>
                  food, cost = search(abbrv)<br>
                  if cost > MAX_COST:
                  <div class="tabbed">
                    continue
                  </div>
                  addToVisual(food)<br>
                  queryRecipes(food)
                </div>
              </div>
            </div>
          </div>
          <div class="algo">
            function search(abbrv):
            <div class="tabbed">
              min_cost = infinity<br>
              closest_food = null<br>
              for keywords, food in dataset:
              <div class="tabbed">
                total_cost = 0<br>
                for word in abbrv:
                <div class="tabbed">
                  keyword_min_cost = infinity<br>
                  for keyword in keywords:
                  <div class="tabbed">
                    keyword_cost = edit_distance(word, keyword)<br>
                    if keyword_cost < keyword_min_cost:
                    <div class="tabbed">
                      keyword_min_cost = keyword_cost
                    </div>
                  </div>
                  total_cost += keyword_min_cost
                </div>
                avg_cost = total_cost / abbrv.word_count<br>
                name_cost = edit_distance(abbrv, food)<br>
                true_cost = (P * name_cost + (1 - P) * avg_cost) / abbrv.length<br>
                if true_cost < min_cost:
                <div class="tabbed">
                  closest_food = food
                  min_cost = true_cost
                </div>
              </div>
              return closest_food, min_cost
            </div>
          </div>
          <div class="algo">
            function edit_distance(abbrv, food):
            <div class="tabbed">
              dp = zero_matrix(abbrv.length + 1, food.length + 1)<br>
              for i from 0 to abbrv.length:
              <div class="tabbed">
                for j from 0 to food.length:
                <div class="tabbed">
                  if i == 0:
                  <div class="tabbed">
                    dp[i, j] = j * INSERTION_COST
                  </div>
                  else if j == 0:
                  <div class="tabbed">
                    dp[i, j] = i * DELETION_COST
                  </div>
                  else if abbrv[i - 1] == food[j - 1]:
                  <div class="tabbed">
                    dp[i, j] = dp[i - 1, j - 1]
                  </div>
                  else:
                  <div class="tabbed">
                    dp[i, j] = min(
                    <div class="tabbed">
                      dp[i][j - 1] + INSERTION_COST,<br>
                      dp[i - 1][j] + DELETION_COST,<br>
                      dp[i - 1][j - 1] + INSERTION_COST + DELETION_COST
                    </div>
                    )
                  </div>
                </div>
              </div>
              return dp[abbrv.length, food.length]
            </div>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">User Experience</div>
          <div class="text">
            1. Suppose the user goes grocery shopping and returns with the following receipt (I just found this online).
          </div>
          <div class="image-container">
            <img width="20%" src="assets/frijma/receipt.jpg">
          </div>
          <div class="text">
            2. The user either takes a photo or uploads an image of their receipt.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/frijma/scan.png">
          </div>
          <div class="text">
            3. Frijma provides a list of all of the groceries detected on the receipt with their expiration dates.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/frijma/result.png">
          </div>
          <div class="text">
            4. Frijma also provides a list of relevant recipes to help use up all of your groceries on time.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/frijma/recipes.png">
          </div>
        </div>
      </div>

      <div id="project-sidewalk" class="section">
        <div class="header">Project Sidewalk</div>
        <div class="date">Sep 2021 - Jun 2022</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            In 2020, I joined the UW Makeability Lab as a software engineer, co-developing the Project Sidewalk webpage:
            a gameified website where users walk around in Google Street View and label sidewalk accessibility issues for wheelchair
            users and older adults. Since deployment, we were able to build a never-seen-before dataset of 1 million labels
            across 8 cities.
          </div>
          <div class="text">
            In 2021, I joined forces with my friends Michael and Logan to apply deep learning to the above dataset to
            create a computer vision pipeline for automatic sidwealk evaluation. As a culmination of our work, we authored
            a paper discussing the effects of filtered vs. unfiltered and single-city vs. cross-city training data and
            how our models can label new cities with a promising 80-90% accuracy. Our paper was accepted to the ASSETS
            conference in Oct 2022.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Links</div>
          <ul class="list">
            <li>Sidewalk Webpage: <a href="https://sidewalk-sea.cs.washington.edu" target="_blank">https://sidewalk-sea.cs.washington.edu</a></li>
            <li>Sidewalk Webpage Code: <a href="https://github.com/ProjectSidewalk/SidewalkWebpage" target="_blank">https://github.com/ProjectSidewalk/SidewalkWebpage</a></li>
            <li>Sidewalk CV Code: <a href="https://github.com/michaelduan8/sidewalk-cv-2021" target="_blank">https://github.com/michaelduan8/sidewalk-cv-2021</a></li>
            <li>Publication: <a href="https://dl.acm.org/doi/10.1145/3517428.3550381" target="_blank">https://dl.acm.org/doi/10.1145/3517428.3550381</a></li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Software & Tools</div>
          <ul class="list">
            <li>Sidewalk Webpage Languages: PostgreSQL, Scala, JavaScript, HTML, CSS</li>
            <li>Sidewalk CV Languages: Python, Bash</li>
            <li>Street View API: Google Street View</li>
            <li>ML Library: PyTorch</li>
            <li>Util Libraries: Pandas, Matplotlib</li>
            <li>Paper: LaTeX</li>
          </ul>
        </div>
        <div class="subsection">
          <div class="subheader">Data Collection</div>
          <div class="text">
            Here's a screenshot of the Project Sidewalk webpage for crowdsourcing labels. I worked on many features
            including visualizing the users observed area in the bottom right corner that improved data quality by
            incentivizing users to look around.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/project_sidewalk/webpage.png">
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Publication</div>
          <div class="pdf">
            <iframe height="830" width="600" src="assets/project_sidewalk/paper.pdf"></iframe>
          </div>
        </div>
      </div>

      <div id="danzon" class="section">
        <div class="header">Danzón No. 2</div>
        <div class="date">Jul 2019 - Aug 2021</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            I first played Danzón No. 2 by Arturo Márquez in my high school orchestra and I immediately fell in love with
            the catchy melodies and energetic rhythms. Danzón is a style of dance originating in Cuba and popularized
            in Mexico, and I felt compelled to arrange this piece because it is so fun to play and so that my friends
            and I could spread this type of music into the otherwise eurocentric world of classical music. Also, after
            years of pouring over this score, this is easily my most thought out (and also most difficult) arrangement.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Full Score</div>
          <div class="pdf">
            <iframe height="830" width="600" src="assets/danzon/score.pdf"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Notable Excerpts</div>
          <div class="text">
            The piece begins with the iconic clarinet theme in the first cello and the baseline/clave rhythm in the second cello.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/1.png">
          </div>
          <div class="text">
            The first notoriously difficult section comes during the "Poco più mosso" at bar 66. In the original score, the strings
            are in octaves playing the theme in the first cello part and the woodwinds are playing a very high rhythmic counter theme.
            I initially tried putting that counter theme in the second cello part, but it was too overpowering, so instead I decided
            to reinforce the first cello theme in the second cello but with open strings and harmonics interspersed, simulating the
            effect of the counter theme.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/2.png">
          </div>
          <div class="text">
            The second notoriously difficult section, "Con fuoco", is also most people's favorite. Here, the two cellos trade off
            a catchy theme from the brass/woodwinds and an energetic counterpart from the rest of the strings. When played
            at tempo, it is super difficult to make the far and frequent shifts sound clean and to ensure the clarity of
            articulation in the eigth notes.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/3.png">
          </div>
          <div class="text">
            Another part that's slightly awkward is the second cello part after the "Con fuoco" when I tried to capture the effect of an entire string
            orchestra plucking away.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/4.png">
          </div>
          <div class="text">
            My favorite part of the entire piece is the tempo primo. After an energetic and dissonant build up, the music
            releases into an impactful recap; the second cello begins an epic double-stop section as the first theme returns
            in the first cello. The second cello part is just barely playeable.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/5.png">
          </div>
          <div class="text">
            In my opinion, by far the hardest section is the return of the super high second theme in bar 198. It's just
            very exposed and you have to cleanly execute shifts in an awkward register. I decided to end the section with
            harmonics to mimic the color of a flute and clarinet.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/6.png">
          </div>
          <div class="text">
            The end of the piece consists of a gradual 16 bar crescendo where instruments from the symphony join one at a time.
            I simulated this by not only including the crescendo itself, but also gradually climbing octaves and incorporating
            double-stops.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/danzon/7.png">
          </div>
        </div>
      </div>

      <div id="cinema-paradiso" class="section">
        <div class="header">Cinema Paradiso</div>
        <div class="date">Aug 2020 - Feb 2021</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Cinema Paradiso by Giuseppe Tornatore is a movie set in a small Sicilian town and covers themes such as love,
            loss, and nostalgia. The soundtrack, by Ennio Morricone, is some of my favorite movie scoring ever, and so I
            had to arrange it for two cellos. I ended up picking out iconic themes from the soundtrack, transcribing
            them by ear while adding in my own artistic touch, and stitching everything together into a sort of theme and
            variations which I feel tells a compelling and cohesive story.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Full Score</div>
          <div class="pdf">
            <iframe height="830" width="600" src="assets/cinema_paradiso/score.pdf"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Notable Excerpts</div>
          <div class="text">
            The piece opens with a b-flat major arpeggio and 16-th note ornaments that leads into the introductory theme
            that reminds me of a sunrise with birds chirping away.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/1.png">
          </div>
          <div class="text">
            The famous love theme, tema d'amore, is first introduced in bar 33, the subject of the theme and variations. I started with
            a simple pizzicato part in the second cello outlining the chords. This theme gets repeated 4 times in a row,
            two at a lower octave and two at a higher octave, each increasing in dynamics and complexity.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/2.png">
          </div>
          <div class="text">
            In bar 72, we take a break from the love theme and introduce the "Infanzia" theme, symbolizing young/naive love. The
            two cellos trade off a simple theme with playful pizzicato.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/3.png">
          </div>
          <div class="text">
            In the movie, the infanzia theme is often immediately followed by the "Maturità" theme, which features a rich
            melody played in the deeper register of the cello. The legato symbolizes rounded out wisdom and the two cellos
            playing in the similar octave symbolize the union of the two individualze's values (as opposed to the contrasting
            parts in the "Infanzia" theme). 
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/4.png">
          </div>
          <div class="text">
            "Cinema in Fiamme" is a theme that plays only once in the entire movie right before disaster strikes. To make
            it especially climactic, I decided to double the theme across both parts, with an alternating arppegiated motif
            for added emphasis.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/5.png">
          </div>
          <div class="text">
            Following the aftermath of the disaster, the love theme returns again in bar 157. Although this time,
            the accompaniment is a heartwrenching counter-melody with swirling chromaticism and becomes quite difficult
            as I try to capture multiple voices into a single part. Like before, the love theme repeats several more
            times, each increasing in intensity and grandeur. 
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/6.png">
          </div>
          <div class="text">
            In my opinion, the hardest part by far is the first cello accompaniment of the penultimate love theme. No need
            to explain, just try playing it.
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/7.png">
          </div>
          <div class="text">
            The piece reaches a rather grand resolution in bar 205 which easily sounds like it could be the end of the piece.
            However, I decided to add one last theme, "Ripensandola", which roughly translates to "Thinking About Her Again."
            The theme is a soft, broken version of the love theme, where each chord swells like a breath. My hope was to capture
            the nostalgic and cathartic reflections of one who's lover has passed away. 
          </div>
          <div class="image-container">
            <img width="80%" src="assets/cinema_paradiso/8.png">
          </div>
        </div>
      </div>

      <div id="cello" class="section">
        <div class="header">Cello</div>
        <div class="date">Nov 2005 - Present</div>
        <div class="subsection">
          <div class="subheader">Abstract</div>
          <div class="text">
            Here are some random videos of me playing cello with friends.
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Some Improv</div>
          <div class="text">
            04/08/2023<br>
            Guitar: Arjun Srivastava<br>
            Cello: Sho Kiami<br>
            Keyboard: Pranav Bhagavatula<br>
            Arjun, Pranav, and I like to hold jam sessions every once in a while and here is a clip from one of those days.
            The result was some e-minor bossa nova type vibe.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/d406VDctxPE?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Chopin - Cello Sonata, III. Largo</div>
          <div class="text">
            10/13/2022<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            Michael and I have been working on the Chopin Cello Sonata for some time now, and the third movement has always
            been a favorite due to its simplicity and beauty.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/AO0mVYODYWk?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Rachmaninoff - Cello Sonata, III. Andante (Arr. Sho Kiami)</div>
          <div class="text">
            12/20/2021<br>
            Cello 1: Sho Kiami<br>
            Cello 2: Yuta Kiami<br>
            Yuta had been working on the Rachmaninoff Cello Sonata and asked if I could arrange the piano part for cello and
            play it with him at a music night hosted by some friends. I thought the arrangement actually turned out quite
            well considering the fact that the piano part is notoriously complex.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/VcukGP_2XTY?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Arnesen - Magnificat</div>
          <div class="text">
            12/12/2021<br>
            University Presbyterian Church Choir<br>
            Various Musicians from Seattle<br>
            My old cello teacher, Rajan Krishnaswami, invited me to play this professional gig with him so I had to pull
            through. The performance was rather long and I wanted to highlight a piece called Magnificat written in 2010 by
            Norwegian composer Kim André Arnesen. This piece has easily some of the most beautiful harmonies I've ever heard
            and I especially love the final movement "Gloria Patri" starting at 54:18.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/MLoWVUZ3JVE?rel=0&start=1372&end=3743" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Bloch - From Jewish Life, I. Prayer</div>
          <div class="text">
            10/12/2021<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            This piece is inspired by prayers sung in Ashkenazi synagogues. It holds a special place in my heart as it is
            haungtingly gorgeous and sounds very human. Also, I think it works so well on the cello.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/JXZTA46R1Nk?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Handel/Halvorsen - Passacaglia</div>
          <div class="text">
            05/16/2021<br>
            Violin: Takumi Taguchi<br>
            Cello: Sho Kiami<br>
            Passacaglia is one of the classic violin-cello duets, and Takumi and I felt like sight-reading it for fun.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/CBiAg2KJN9w?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Piazzolla - Le Grand Tango</div>
          <div class="text">
            9/21/2020<br>
            Cello: Sho Kiami<br>
            Piano: Michael Duan<br>
            I really really love Argentine tango and so I had to share this piece with Michael. This was actually our first
            time playing together and it led to many more years of music together.
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/duuRF5fG5sM?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
        <div class="subsection">
          <div class="subheader">Strauss - Der Rosenkavalier Suite</div>
          <div class="text">
            08/05/2018<br>
            Marrowstone Music Festival Symphony Orchestra<br>
            This piece might be my favorite symphonic piece ever. Listen from 15:16 for one of the most sublime moments
            in all of music. 
          </div>
          <div class="youtube">
            <iframe height="360" width="640" src="https://www.youtube.com/embed/sEelWL_qu1s?rel=0" frameborder="0" allowfullscreen loading="lazy"></iframe>
          </div>
        </div>
      </div>

      <div id="contact" class="section">
        <div class="header">Contact Me</div>
        <div class="date"></div>
        <div class="subsection">
          <ul>
            <li>
              <i class="fa fa-envelope"></i>
              <a href="mailto:kiami.sho@gmail.com">kiami.sho@gmail.com</a>
            </li>
            <li>
              <i class="fa fa-phone"></i>
              <a>+1 (206) 383-5764</a>
            </li>
            <li>
              <i class="fa fa-linkedin-square"></i>
              <a href="https://linkedin.com/in/shokiami">linkedin.com/in/shokiami</a>
            </li>
            <li>
              <i class="fa fa-github"></i>
              <a href="https://github.com/shokiami">github.com/shokiami</a>
            </li>
          </ul>
        </div>
      </div>

      <div id="footer">© 2023 Shosuke C. Kiami</div>
    </div>
    <div id="image-container"></div>
    <script src="main.js"></script>
  </body>
</html>
